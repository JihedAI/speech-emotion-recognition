{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT NECESSARY LIBRARIES\n",
    "import librosa\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os # interface with underlying OS that python is running on\n",
    "import sys\n",
    "import warnings\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization, Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE DIRECTORY OF AUDIO FILES \n",
    "audio = \"C:/Users/21652/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24\"\n",
    "actor_folders = os.listdir(audio) #list files in audio directory\n",
    "actor_folders.sort() \n",
    "actor_folders[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FUNCTION TO EXTRACT EMOTION NUMBER, ACTOR AND GENDER LABEL\n",
    "emotion = []\n",
    "gender = []\n",
    "actor = []\n",
    "file_path = []\n",
    "for i in actor_folders:\n",
    "    filename = os.listdir(audio +'/'+ i) #iterate over Actor folders\n",
    "    for f in filename: # go through files in Actor folder\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        actor.append(int(part[6]))\n",
    "        bg = int(part[6])\n",
    "        if bg%2 == 0:\n",
    "            bg = \"female\"\n",
    "        else:\n",
    "            bg = \"male\"\n",
    "        gender.append(bg)\n",
    "        file_path.append(audio+ '/' + i + '/' +f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>actor</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>female</td>\n",
       "      <td>fear</td>\n",
       "      <td>24</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>female</td>\n",
       "      <td>fear</td>\n",
       "      <td>24</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>female</td>\n",
       "      <td>fear</td>\n",
       "      <td>24</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>female</td>\n",
       "      <td>fear</td>\n",
       "      <td>24</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>female</td>\n",
       "      <td>fear</td>\n",
       "      <td>24</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  emotion  actor  \\\n",
       "0       male  neutral      1   \n",
       "1       male  neutral      1   \n",
       "2       male  neutral      1   \n",
       "3       male  neutral      1   \n",
       "4       male     calm      1   \n",
       "...      ...      ...    ...   \n",
       "1007  female     fear     24   \n",
       "1008  female     fear     24   \n",
       "1009  female     fear     24   \n",
       "1010  female     fear     24   \n",
       "1011  female     fear     24   \n",
       "\n",
       "                                                   path  \n",
       "0     C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...  \n",
       "1     C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...  \n",
       "2     C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...  \n",
       "3     C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...  \n",
       "4     C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...  \n",
       "...                                                 ...  \n",
       "1007  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...  \n",
       "1008  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...  \n",
       "1009  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...  \n",
       "1010  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...  \n",
       "1011  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_R...  \n",
       "\n",
       "[1012 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PUT EXTRACTED LABELS WITH FILEPATH INTO DATAFRAME\n",
    "audio_df = pd.DataFrame(emotion)\n",
    "audio_df = audio_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "audio_df = pd.concat([pd.DataFrame(gender),audio_df,pd.DataFrame(actor)],axis=1)\n",
    "audio_df.columns = ['gender','emotion','actor']\n",
    "audio_df = pd.concat([audio_df,pd.DataFrame(file_path, columns = ['path'])],axis=1)\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>actor</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>female</td>\n",
       "      <td>calm</td>\n",
       "      <td>14</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_14/03-02-02-02-02-02-14.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "      <td>22</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_22/03-02-05-02-02-01-22.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "      <td>9</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_09/03-02-02-01-01-01-09.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>female</td>\n",
       "      <td>calm</td>\n",
       "      <td>4</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_04/03-02-02-02-02-02-04.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>male</td>\n",
       "      <td>sad</td>\n",
       "      <td>9</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_09/03-02-04-02-01-02-09.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_03/03-02-01-01-01-01-03.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>male</td>\n",
       "      <td>sad</td>\n",
       "      <td>5</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_05/03-02-04-02-01-02-05.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>male</td>\n",
       "      <td>fear</td>\n",
       "      <td>21</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_21/03-02-06-01-01-01-21.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>23</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_23/03-02-01-01-01-01-23.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>male</td>\n",
       "      <td>happy</td>\n",
       "      <td>9</td>\n",
       "      <td>C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_09/03-02-03-01-02-01-09.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  emotion  actor  \\\n",
       "583  female  calm     14      \n",
       "914  female  angry    22      \n",
       "356  male    calm     9       \n",
       "143  female  calm     4       \n",
       "377  male    sad      9       \n",
       "88   male    neutral  3       \n",
       "201  male    sad      5       \n",
       "872  male    fear     21      \n",
       "924  male    neutral  23      \n",
       "366  male    happy    9       \n",
       "\n",
       "                                                                                                                                                            path  \n",
       "583  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_14/03-02-02-02-02-02-14.wav  \n",
       "914  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_22/03-02-05-02-02-01-22.wav  \n",
       "356  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_09/03-02-02-01-01-01-09.wav  \n",
       "143  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_04/03-02-02-02-02-02-04.wav  \n",
       "377  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_09/03-02-04-02-01-02-09.wav  \n",
       "88   C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_03/03-02-01-01-01-01-03.wav  \n",
       "201  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_05/03-02-04-02-01-02-05.wav  \n",
       "872  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_21/03-02-06-01-01-01-21.wav  \n",
       "924  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_23/03-02-01-01-01-01-23.wav  \n",
       "366  C:/Users/Jawher/Desktop/jihed/Speech_Emotion_Recognition-master/Speech_Emotion_Recognition-master/Audio_Song_Actors_01-24/Actor_09/03-02-03-01-02-01-09.wav  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ENSURE GENDER,EMOTION, AND ACTOR COLUMN VALUES ARE CORRECT\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "audio_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOOK AT DISTRIBUTION OF CLASSES\n",
    "audio_df.emotion.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mel_spectrogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.190216, -68.49858, -69.23745, -70.66261, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -69.54066, -66.911156, -67.440575, -70.47629, -70.67003, -70.67003, -70.628746, -59.254734, -43.85587, -40.168777, -41.190712, -43.157154, -44.008953, -40.533142, -37.10629, -34.757618, -32.68789, -31.242712, -30.120289, -29.687452, -29.560444, -28.877934, -29.341787, -30.94304, -33.464615, -38.88975, -43.080807, -45.807068, -46.199223, -45.987682, -44.60737, -42.585197, -41.126144, -38.51099, -35.71651, -32.96074, -31.02113, -29.765602, -28.952774, -28.531687, -27.539211, -26.62564, -26.87324, -27.474485, -28.6087, -29.16343, -28.684006, -27.88769, -27.964436, -30.570744, -35.62474, -40.347336, -43.384968, -45.963387, -43.16702, -34.02387, -32.436672, -34.492157, -33.694843, -33.73878, -33.381107, -33.560535, -34.43642, -33.960354, -33.16808, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.04893, -60.11285, -45.350937, -42.00334, -41.741093, -41.91916, -43.271397, -43.133457, -37.824593, -34.305923, -31.937103, -30.453232, -29.497656, -28.785917, -28.187498, -28.061852, -27.69304, -26.917662, -27.700888, -27.459026, -28.016289, -31.628357, -37.958668, -40.81501, -42.368633, -43.840466, -43.424545, -42.202934, -40.88009, -39.053875, -35.384518, -30.63461, -27.908628, -26.501371, -26.061802, -27.090551, -26.300945, -25.959005, -26.737139, -26.107529, -25.980377, -27.159588, -27.926327, -28.559776, -28.601318, -28.349365, -28.043934, -27.009586, -30.559622, -36.29083, -38.025787, -41.260357, -43.106167, -35.34729, -33.36584, -36.46488, -35.779747, -35.02356, -35.06164, -33.27595, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.798965, -67.38703, -67.21093, -67.03594, -49.46283, -39.598106, -34.318638, -31.077501, -30.176928, -28.498196, -28.264261, -28.873087, -28.981672, -28.520302, -27.99346, -28.29248, -28.153105, -28.301838, -28.545235, -29.830221, -29.78998, -30.552116, -33.21595, -36.99859, -41.46521, -43.18827, -42.553135, -36.735172, -33.153793, -32.836678, -33.406464, -32.764217, -29.826664, -27.830383, -28.27728, -28.424406, -28.546946, -28.41256, -28.114231, -29.045624, -29.830849, -30.05784, -29.242104, -28.03939, -27.667528, -28.419981, -28.537123, -29.107044, -29.651337, -30.34374, -31.182333, -31.939127, -32.60005, -33.40206, -34.381355, -35.294464, -35.175167, -34.42055, -33.495834, -34.229874, -29.979872, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.14961, -69.297646, -67.8701, -68.44447, -69.588104, -69.63423, -69.63423, -69.63423, -69.63423, -69.37452, -69.34724, -69.63423, -69.54584, -69.63423, -69.417465, -68.65891, -67.201614, -67.55465, -65.11445, -40.985256, -33.195805, -29.177753, -27.830856, -27.019705, -26.827806, -27.341864, -27.959696, -28.428802, -29.598585, -29.603374, -28.9081, -27.898201, -27.15809, -27.86456, -28.94813, -29.239513, -30.458084, -32.03817, -35.835487, -39.668, -39.920258, -37.35394, -37.106598, -37.41889, -38.22456, -35.983505, -32.081684, -29.34776, -29.567549, -28.597185, -27.98097, -27.751215, -28.248798, -28.276268, -27.968502, -28.903387, -29.842196, -30.842264, -30.399366, -30.831446, -31.574036, -31.024265, -31.345745, -31.435415, -31.26777, -32.232857, -32.639164, -32.98872, -33.76681, -34.88316, -35.22872, -35.275475, -34.061672, -34.93693, -35.767693, -31.900803, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-70.88479, -70.865654, -70.86494, -70.88479, -70.444595, -70.051346, -70.29029, -70.42655, -70.55085, -70.64131, -70.60913, -70.226135, -70.40858, -70.4901, -70.43125, -69.87342, -69.76289, -69.97025, -70.32783, -70.38158, -70.74335, -70.78462, -70.67027, -70.24939, -70.72296, -70.680466, -70.858185, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.68384, -70.52328, -70.63528, -70.51344, -59.273663, -47.150772, -44.03397, -43.184525, -44.460518, -47.782154, -49.423138, -48.688145, -44.60635, -39.784264, -36.076633, -34.244884, -33.011395, -31.457802, -30.842249, -30.264315, -29.867659, -30.851053, -30.580982, -29.6901, -30.100834, -30.673271, -31.044662, -31.316631, -31.482117, -32.938465, -33.14895, -35.896835, -39.381863, -41.166958, -41.13847, -40.472042, -38.83351, -36.543823, -30.86093, -30.124899, -31.448725, -30.981667, -30.102644, -28.711485, -29.424456, -29.52495, -29.469028, -28.606459, -28.469656, -30.023882, -31.449877, -31.924152, -31.503937, -32.066315, -31.628551, -30.378786, -31.124859, -36.62465, -41.74159, -45.029327, -39.192326, -34.90151, -31.002739, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          mel_spectrogram\n",
       "0  [-70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.190216, -68.49858, -69.23745, -70.66261, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -70.67003, -69.54066, -66.911156, -67.440575, -70.47629, -70.67003, -70.67003, -70.628746, -59.254734, -43.85587, -40.168777, -41.190712, -43.157154, -44.008953, -40.533142, -37.10629, -34.757618, -32.68789, -31.242712, -30.120289, -29.687452, -29.560444, -28.877934, -29.341787, -30.94304, -33.464615, -38.88975, -43.080807, -45.807068, -46.199223, -45.987682, -44.60737, -42.585197, -41.126144, -38.51099, -35.71651, -32.96074, -31.02113, -29.765602, -28.952774, -28.531687, -27.539211, -26.62564, -26.87324, -27.474485, -28.6087, -29.16343, -28.684006, -27.88769, -27.964436, -30.570744, -35.62474, -40.347336, -43.384968, -45.963387, -43.16702, -34.02387, -32.436672, -34.492157, -33.694843, -33.73878, -33.381107, -33.560535, -34.43642, -33.960354, -33.16808, ...]                                             \n",
       "1  [-68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.248024, -68.04893, -60.11285, -45.350937, -42.00334, -41.741093, -41.91916, -43.271397, -43.133457, -37.824593, -34.305923, -31.937103, -30.453232, -29.497656, -28.785917, -28.187498, -28.061852, -27.69304, -26.917662, -27.700888, -27.459026, -28.016289, -31.628357, -37.958668, -40.81501, -42.368633, -43.840466, -43.424545, -42.202934, -40.88009, -39.053875, -35.384518, -30.63461, -27.908628, -26.501371, -26.061802, -27.090551, -26.300945, -25.959005, -26.737139, -26.107529, -25.980377, -27.159588, -27.926327, -28.559776, -28.601318, -28.349365, -28.043934, -27.009586, -30.559622, -36.29083, -38.025787, -41.260357, -43.106167, -35.34729, -33.36584, -36.46488, -35.779747, -35.02356, -35.06164, -33.27595, ...]\n",
       "2  [-67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.80903, -67.798965, -67.38703, -67.21093, -67.03594, -49.46283, -39.598106, -34.318638, -31.077501, -30.176928, -28.498196, -28.264261, -28.873087, -28.981672, -28.520302, -27.99346, -28.29248, -28.153105, -28.301838, -28.545235, -29.830221, -29.78998, -30.552116, -33.21595, -36.99859, -41.46521, -43.18827, -42.553135, -36.735172, -33.153793, -32.836678, -33.406464, -32.764217, -29.826664, -27.830383, -28.27728, -28.424406, -28.546946, -28.41256, -28.114231, -29.045624, -29.830849, -30.05784, -29.242104, -28.03939, -27.667528, -28.419981, -28.537123, -29.107044, -29.651337, -30.34374, -31.182333, -31.939127, -32.60005, -33.40206, -34.381355, -35.294464, -35.175167, -34.42055, -33.495834, -34.229874, -29.979872, ...]                                           \n",
       "3  [-69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.63423, -69.14961, -69.297646, -67.8701, -68.44447, -69.588104, -69.63423, -69.63423, -69.63423, -69.63423, -69.37452, -69.34724, -69.63423, -69.54584, -69.63423, -69.417465, -68.65891, -67.201614, -67.55465, -65.11445, -40.985256, -33.195805, -29.177753, -27.830856, -27.019705, -26.827806, -27.341864, -27.959696, -28.428802, -29.598585, -29.603374, -28.9081, -27.898201, -27.15809, -27.86456, -28.94813, -29.239513, -30.458084, -32.03817, -35.835487, -39.668, -39.920258, -37.35394, -37.106598, -37.41889, -38.22456, -35.983505, -32.081684, -29.34776, -29.567549, -28.597185, -27.98097, -27.751215, -28.248798, -28.276268, -27.968502, -28.903387, -29.842196, -30.842264, -30.399366, -30.831446, -31.574036, -31.024265, -31.345745, -31.435415, -31.26777, -32.232857, -32.639164, -32.98872, -33.76681, -34.88316, -35.22872, -35.275475, -34.061672, -34.93693, -35.767693, -31.900803, ...]                                             \n",
       "4  [-70.88479, -70.865654, -70.86494, -70.88479, -70.444595, -70.051346, -70.29029, -70.42655, -70.55085, -70.64131, -70.60913, -70.226135, -70.40858, -70.4901, -70.43125, -69.87342, -69.76289, -69.97025, -70.32783, -70.38158, -70.74335, -70.78462, -70.67027, -70.24939, -70.72296, -70.680466, -70.858185, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.88479, -70.68384, -70.52328, -70.63528, -70.51344, -59.273663, -47.150772, -44.03397, -43.184525, -44.460518, -47.782154, -49.423138, -48.688145, -44.60635, -39.784264, -36.076633, -34.244884, -33.011395, -31.457802, -30.842249, -30.264315, -29.867659, -30.851053, -30.580982, -29.6901, -30.100834, -30.673271, -31.044662, -31.316631, -31.482117, -32.938465, -33.14895, -35.896835, -39.381863, -41.166958, -41.13847, -40.472042, -38.83351, -36.543823, -30.86093, -30.124899, -31.448725, -30.981667, -30.102644, -28.711485, -29.424456, -29.52495, -29.469028, -28.606459, -28.469656, -30.023882, -31.449877, -31.924152, -31.503937, -32.066315, -31.628551, -30.378786, -31.124859, -36.62465, -41.74159, -45.029327, -39.192326, -34.90151, -31.002739, ...]                                 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ITERATE OVER ALL AUDIO FILES AND EXTRACT LOG MEL SPECTROGRAM MEAN VALUES INTO DF FOR MODELING \n",
    "df = pd.DataFrame(columns=['mel_spectrogram'])\n",
    "\n",
    "counter=0\n",
    "\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=3,sr=44100,offset=0.5)\n",
    "    \n",
    "    #get the mel-scaled spectrogram (ransform both the y-axis (frequency) to log scale, and the “color” axis (amplitude) to Decibels, which is kinda the log scale of amplitudes.)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128,fmax=8000) \n",
    "    db_spec = librosa.power_to_db(spectrogram)\n",
    "    #temporally average spectrogram\n",
    "    log_spectrogram = np.mean(db_spec, axis = 0)\n",
    "        \n",
    "    # Mel-frequency cepstral coefficients (MFCCs)\n",
    "#     mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "#     mfcc=np.mean(mfcc,axis=0)\n",
    "    \n",
    "    # compute chroma energy (pertains to 12 different pitch classes)\n",
    "#     chroma = librosa.feature.chroma_stft(y=X, sr=sample_rate)\n",
    "#     chroma = np.mean(chroma, axis = 0)\n",
    "\n",
    "    # compute spectral contrast\n",
    "#     contrast = librosa.feature.spectral_contrast(y=X, sr=sample_rate)\n",
    "#     contrast = np.mean(contrast, axis= 0)\n",
    "\n",
    "    # compute zero-crossing-rate (zcr:the zcr is the rate of sign changes along a signal i.e.m the rate at \n",
    "#     which the signal changes from positive to negative or back - separation of voiced andunvoiced speech.)\n",
    "#     zcr = librosa.feature.zero_crossing_rate(y=X)\n",
    "#     zcr = np.mean(zcr, axis= 0)\n",
    "    \n",
    "    df.loc[counter] = [log_spectrogram]\n",
    "    counter=counter+1   \n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -62.151554, -62.328453, -63.07476, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.194283, -60.849426, -60.895798, -61.387733, -61.437893, -61.437893, -61.107216, -59.857037, -45.711346, -38.889267, -36.53251, -37.097466, -29.732597, -24.980236, -23.902977, -23.12183, -23.740465, -23.634695, -23.733448, -23.417091, -24.51813, -24.052935, -23.994926, -26.18621, -26.488516, -28.457066, -33.56494, -33.786774, -32.338387, -31.367708, -31.428806, -31.794638, -32.398094, -30.941545, -29.507961, -27.379284, -27.746504, -30.799679, -31.11086, -30.73749, -31.979618, -29.969563, -30.01867, -29.887747, -30.655132, -30.809042, -30.45988, -29.504639, -26.850895, -27.134636, -28.018301, -28.805264, -32.4379, -36.561344, -33.46091, -27.21954, -27.15051, -30.39628, -30.844906, -30.562675, -31.41053, -31.650465, -29.03514, -29.230604, -30.388216, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -57.675797, -53.893414, -42.789917, -40.250244, -40.629208, -42.34266, -39.69204, -29.89987, -23.982357, -24.059319, -23.106676, -22.121826, -22.475166, -22.930696, -24.125347, -23.599743, -22.205025, -21.217861, -21.227793, -21.362333, -21.95323, -22.648094, -26.720402, -27.806334, -28.640095, -27.413597, -28.016174, -30.850197, -30.765919, -28.470877, -28.007437, -27.361217, -26.670559, -26.977987, -29.26652, -27.943869, -27.619408, -26.932304, -26.770905, -27.296904, -27.59283, -27.898813, -29.234978, -29.789806, -29.46861, -29.16602, -29.115984, -25.59075, -28.235512, -27.964903, -28.265759, -32.67519, -33.862663, -30.653385, -28.512505, -29.214296, -29.390547, -32.072197, -30.264906, -25.857182, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.412888, -59.419876, -59.408348, -58.46498, -54.950474, -51.930233, -36.84047, -27.648485, -22.351257, -21.238243, -22.773388, -21.780539, -21.096355, -23.170208, -23.634373, -22.40959, -21.390171, -21.690147, -22.50355, -23.61407, -24.191704, -25.496609, -25.469908, -27.605389, -27.38091, -27.057125, -29.258772, -30.141937, -30.287708, -28.628237, -27.342588, -27.996609, -28.568132, -28.152191, -25.253448, -25.443441, -26.135363, -26.53722, -27.59862, -28.882204, -29.089651, -29.619854, -30.22004, -30.089996, -29.309004, -28.5656, -27.698202, -26.383314, -23.68207, -24.808628, -24.247831, -25.107601, -27.937117, -29.58547, -30.154179, -31.243727, -34.24955, -35.292553, -32.558823, -31.06132, -32.70069, -30.248348, -26.00769, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -58.9715, -59.314285, -58.802322, -59.354763, -60.654396, -61.265728, -61.265728, -61.265728, -61.265728, -61.116245, -61.062664, -61.265728, -60.01496, -61.265728, -60.6819, -58.12982, -52.940434, -53.090805, -54.78672, -38.824795, -26.25977, -24.163004, -24.095106, -24.659426, -23.017233, -23.26418, -22.930021, -23.181002, -23.751574, -24.14382, -24.213165, -25.949589, -24.089058, -25.778093, -26.32416, -24.544746, -25.672665, -27.264212, -27.769386, -27.918892, -29.636929, -27.935932, -26.831734, -26.814678, -28.984545, -28.212517, -26.771873, -25.99805, -27.737764, -26.99108, -26.922295, -27.135714, -27.32268, -27.372131, -27.671757, -28.622152, -28.60741, -30.352581, -29.430666, -29.258858, -28.245924, -26.456724, -25.163517, -24.330616, -26.391144, -27.88849, -28.465921, -30.335392, -31.919903, -32.660225, -32.946457, -33.16742, -32.824955, -34.356068, -30.682312, -27.04966, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-61.675594, -61.666203, -61.663513, -61.675594, -59.627464, -58.578274, -60.384644, -60.370815, -59.20907, -59.793682, -60.15809, -60.04435, -60.245426, -60.439407, -60.355404, -59.4081, -58.86527, -59.345196, -61.60242, -61.500546, -61.70982, -61.667637, -60.603718, -58.23291, -60.36817, -59.87786, -61.40747, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -60.927265, -58.84497, -60.013573, -58.516964, -49.573547, -40.207928, -37.30262, -35.370815, -36.218803, -37.636074, -39.60809, -33.359314, -27.223022, -24.51279, -23.455894, -22.983889, -23.631773, -23.307129, -22.76468, -21.929472, -21.307625, -22.805206, -22.493216, -22.082146, -22.910034, -23.257229, -24.46086, -24.328066, -25.264225, -26.389513, -25.98093, -26.578896, -25.305767, -25.928038, -26.857933, -27.007057, -28.13866, -28.220612, -26.16967, -26.171253, -25.79583, -25.427229, -25.699423, -26.15977, -27.405, -27.819134, -27.755077, -28.10049, -28.252087, -28.713966, -30.351692, -29.451944, -29.004128, -28.29912, -29.129955, -27.25071, -24.468893, -26.161173, -28.288338, -32.104385, -30.79204, -29.720257, -30.107597, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   mfcc\n",
       "0  [-61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -62.151554, -62.328453, -63.07476, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.437893, -61.194283, -60.849426, -60.895798, -61.387733, -61.437893, -61.437893, -61.107216, -59.857037, -45.711346, -38.889267, -36.53251, -37.097466, -29.732597, -24.980236, -23.902977, -23.12183, -23.740465, -23.634695, -23.733448, -23.417091, -24.51813, -24.052935, -23.994926, -26.18621, -26.488516, -28.457066, -33.56494, -33.786774, -32.338387, -31.367708, -31.428806, -31.794638, -32.398094, -30.941545, -29.507961, -27.379284, -27.746504, -30.799679, -31.11086, -30.73749, -31.979618, -29.969563, -30.01867, -29.887747, -30.655132, -30.809042, -30.45988, -29.504639, -26.850895, -27.134636, -28.018301, -28.805264, -32.4379, -36.561344, -33.46091, -27.21954, -27.15051, -30.39628, -30.844906, -30.562675, -31.41053, -31.650465, -29.03514, -29.230604, -30.388216, ...] \n",
       "1  [-59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -59.76821, -57.675797, -53.893414, -42.789917, -40.250244, -40.629208, -42.34266, -39.69204, -29.89987, -23.982357, -24.059319, -23.106676, -22.121826, -22.475166, -22.930696, -24.125347, -23.599743, -22.205025, -21.217861, -21.227793, -21.362333, -21.95323, -22.648094, -26.720402, -27.806334, -28.640095, -27.413597, -28.016174, -30.850197, -30.765919, -28.470877, -28.007437, -27.361217, -26.670559, -26.977987, -29.26652, -27.943869, -27.619408, -26.932304, -26.770905, -27.296904, -27.59283, -27.898813, -29.234978, -29.789806, -29.46861, -29.16602, -29.115984, -25.59075, -28.235512, -27.964903, -28.265759, -32.67519, -33.862663, -30.653385, -28.512505, -29.214296, -29.390547, -32.072197, -30.264906, -25.857182, ...]                                 \n",
       "2  [-59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.419876, -59.412888, -59.419876, -59.408348, -58.46498, -54.950474, -51.930233, -36.84047, -27.648485, -22.351257, -21.238243, -22.773388, -21.780539, -21.096355, -23.170208, -23.634373, -22.40959, -21.390171, -21.690147, -22.50355, -23.61407, -24.191704, -25.496609, -25.469908, -27.605389, -27.38091, -27.057125, -29.258772, -30.141937, -30.287708, -28.628237, -27.342588, -27.996609, -28.568132, -28.152191, -25.253448, -25.443441, -26.135363, -26.53722, -27.59862, -28.882204, -29.089651, -29.619854, -30.22004, -30.089996, -29.309004, -28.5656, -27.698202, -26.383314, -23.68207, -24.808628, -24.247831, -25.107601, -27.937117, -29.58547, -30.154179, -31.243727, -34.24955, -35.292553, -32.558823, -31.06132, -32.70069, -30.248348, -26.00769, ...]\n",
       "3  [-61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -61.265728, -58.9715, -59.314285, -58.802322, -59.354763, -60.654396, -61.265728, -61.265728, -61.265728, -61.265728, -61.116245, -61.062664, -61.265728, -60.01496, -61.265728, -60.6819, -58.12982, -52.940434, -53.090805, -54.78672, -38.824795, -26.25977, -24.163004, -24.095106, -24.659426, -23.017233, -23.26418, -22.930021, -23.181002, -23.751574, -24.14382, -24.213165, -25.949589, -24.089058, -25.778093, -26.32416, -24.544746, -25.672665, -27.264212, -27.769386, -27.918892, -29.636929, -27.935932, -26.831734, -26.814678, -28.984545, -28.212517, -26.771873, -25.99805, -27.737764, -26.99108, -26.922295, -27.135714, -27.32268, -27.372131, -27.671757, -28.622152, -28.60741, -30.352581, -29.430666, -29.258858, -28.245924, -26.456724, -25.163517, -24.330616, -26.391144, -27.88849, -28.465921, -30.335392, -31.919903, -32.660225, -32.946457, -33.16742, -32.824955, -34.356068, -30.682312, -27.04966, ...] \n",
       "4  [-61.675594, -61.666203, -61.663513, -61.675594, -59.627464, -58.578274, -60.384644, -60.370815, -59.20907, -59.793682, -60.15809, -60.04435, -60.245426, -60.439407, -60.355404, -59.4081, -58.86527, -59.345196, -61.60242, -61.500546, -61.70982, -61.667637, -60.603718, -58.23291, -60.36817, -59.87786, -61.40747, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -61.675594, -60.927265, -58.84497, -60.013573, -58.516964, -49.573547, -40.207928, -37.30262, -35.370815, -36.218803, -37.636074, -39.60809, -33.359314, -27.223022, -24.51279, -23.455894, -22.983889, -23.631773, -23.307129, -22.76468, -21.929472, -21.307625, -22.805206, -22.493216, -22.082146, -22.910034, -23.257229, -24.46086, -24.328066, -25.264225, -26.389513, -25.98093, -26.578896, -25.305767, -25.928038, -26.857933, -27.007057, -28.13866, -28.220612, -26.16967, -26.171253, -25.79583, -25.427229, -25.699423, -26.15977, -27.405, -27.819134, -27.755077, -28.10049, -28.252087, -28.713966, -30.351692, -29.451944, -29.004128, -28.29912, -29.129955, -27.25071, -24.468893, -26.161173, -28.288338, -32.104385, -30.79204, -29.720257, -30.107597, ...]             "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ITERATE OVER ALL AUDIO FILES AND EXTRACT LOG MEL SPECTROGRAM MEAN VALUES INTO DF FOR MODELING \n",
    "df1 = pd.DataFrame(columns=['mfcc'])\n",
    "\n",
    "counter=0\n",
    "\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=3,sr=44100,offset=0.5)\n",
    "    \n",
    "    #get the mel-scaled spectrogram (ransform both the y-axis (frequency) to log scale, and the “color” axis (amplitude) to Decibels, which is kinda the log scale of amplitudes.)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128,fmax=8000) \n",
    "    db_spec = librosa.power_to_db(spectrogram)\n",
    "    #temporally average spectrogram\n",
    "   # log_spectrogram = np.mean(db_spec, axis = 0)\n",
    "        \n",
    "    # Mel-frequency cepstral coefficients (MFCCs)\n",
    "    mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "    mfcc=np.mean(mfcc,axis=0)\n",
    "    \n",
    "    # compute chroma energy (pertains to 12 different pitch classes)\n",
    "#     chroma = librosa.feature.chroma_stft(y=X, sr=sample_rate)\n",
    "#     chroma = np.mean(chroma, axis = 0)\n",
    "\n",
    "    # compute spectral contrast\n",
    "#     contrast = librosa.feature.spectral_contrast(y=X, sr=sample_rate)\n",
    "#     contrast = np.mean(contrast, axis= 0)\n",
    "\n",
    "    # compute zero-crossing-rate (zcr:the zcr is the rate of sign changes along a signal i.e.m the rate at \n",
    "#     which the signal changes from positive to negative or back - separation of voiced andunvoiced speech.)\n",
    "#     zcr = librosa.feature.zero_crossing_rate(y=X)\n",
    "#     zcr = np.mean(zcr, axis= 0)\n",
    "    \n",
    "    df1.loc[counter] = [mfcc]\n",
    "    counter=counter+1   \n",
    "\n",
    "print(len(df1))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0458984375, 0.0458984375, 0.0458984375, 0.0361328125, 0.0, 0.0, 0.01171875, 0.0400390625, 0.0576171875, 0.0576171875, 0.0458984375, 0.017578125, 0.0126953125, 0.0126953125, 0.0126953125, 0.0361328125, 0.0234375, 0.11376953125, 0.203125, 0.32568359375, 0.349609375, 0.34716796875, 0.2763671875, 0.203125, 0.2275390625, 0.15673828125, 0.18115234375, 0.1435546875, 0.11083984375, 0.1220703125, 0.1396484375, 0.1298828125, 0.1376953125, 0.166015625, 0.1640625, 0.22314453125, 0.302734375, 0.37890625, 0.373046875, 0.36279296875, 0.38134765625, 0.4150390625, 0.43896484375, 0.42822265625, 0.35986328125, 0.244140625, 0.20556640625, 0.14599609375, 0.09423828125, 0.04833984375, 0.01318359375, 0.01513671875, 0.01904296875, 0.02294921875, 0.025390625, 0.0263671875, 0.025390625, 0.0224609375, 0.01953125, 0.02197265625, 0.02001953125, 0.02197265625, 0.0224609375, 0.033203125, 0.0419921875, 0.0625, 0.0849609375, 0.0888671875, 0.0947265625, 0.07861328125, 0.05712890625, 0.04248046875, 0.03759765625, 0.0400390625, 0.04541015625, 0.046875, 0.041015625, 0.03564453125, 0.03271484375, 0.029296875, 0.03466796875, 0.03955078125, 0.03955078125, 0.0419921875, 0.03564453125, 0.0302734375, 0.03076171875, 0.02880859375, 0.02734375, 0.05126953125, 0.11767578125, 0.17822265625, 0.22998046875, 0.259765625, 0.23828125, 0.21630859375, 0.18505859375, 0.12841796875, 0.08154296875, 0.04345703125, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.03515625, 0.03515625, 0.03515625, 0.03515625, 0.0, 0.0, 0.0322265625, 0.068359375, 0.1474609375, 0.21826171875, 0.2763671875, 0.2529296875, 0.185546875, 0.138671875, 0.095703125, 0.1845703125, 0.197265625, 0.1845703125, 0.19921875, 0.16064453125, 0.27099609375, 0.3408203125, 0.30322265625, 0.24072265625, 0.10546875, 0.0244140625, 0.0146484375, 0.0146484375, 0.02734375, 0.0390625, 0.1044921875, 0.1669921875, 0.181640625, 0.2568359375, 0.33154296875, 0.3671875, 0.46875, 0.515625, 0.42724609375, 0.3935546875, 0.3212890625, 0.23193359375, 0.216796875, 0.19140625, 0.1396484375, 0.1005859375, 0.056640625, 0.02685546875, 0.03173828125, 0.03759765625, 0.04150390625, 0.04052734375, 0.0380859375, 0.037109375, 0.03515625, 0.0361328125, 0.03466796875, 0.02880859375, 0.021484375, 0.01708984375, 0.0224609375, 0.029296875, 0.05078125, 0.10302734375, 0.1455078125, 0.16943359375, 0.169921875, 0.13037109375, 0.0859375, 0.060546875, 0.04833984375, 0.04248046875, 0.04150390625, 0.03857421875, 0.033203125, 0.0283203125, 0.0263671875, 0.02880859375, 0.0302734375, 0.03271484375, 0.0341796875, 0.03515625, 0.0380859375, 0.0380859375, 0.037109375, 0.03662109375, 0.0322265625, 0.03173828125, 0.037109375, 0.0625, 0.12646484375, 0.20361328125, 0.2666015625, 0.2939453125, 0.271484375, 0.19140625, 0.12109375, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0126953125, 0.0126953125, 0.0126953125, 0.0, 0.0, 0.0, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.0, 0.0, 0.01171875, 0.048828125, 0.16259765625, 0.24560546875, 0.361328125, 0.42578125, 0.43115234375, 0.439453125, 0.39697265625, 0.31396484375, 0.2275390625, 0.140625, 0.06201171875, 0.04931640625, 0.0263671875, 0.0302734375, 0.0302734375, 0.03271484375, 0.029296875, 0.0283203125, 0.0283203125, 0.02783203125, 0.0263671875, 0.02490234375, 0.02392578125, 0.02294921875, 0.0224609375, 0.021484375, 0.01708984375, 0.01318359375, 0.009765625, 0.009765625, 0.01171875, 0.03515625, 0.06005859375, 0.07763671875, 0.0869140625, 0.07373046875, 0.052734375, 0.037109375, 0.03125, 0.02880859375, 0.03125, 0.033203125, 0.03369140625, 0.0322265625, 0.02978515625, 0.0283203125, 0.03173828125, 0.03466796875, 0.03759765625, 0.03759765625, 0.0361328125, 0.04833984375, 0.08740234375, 0.14111328125, 0.18896484375, 0.22119140625, 0.240234375, 0.2431640625, 0.24853515625, 0.2568359375, 0.25146484375, 0.2509765625, 0.24560546875, 0.1982421875, 0.1435546875, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0234375, 0.0234375, 0.095703125, 0.0966796875, 0.1337890625, 0.146484375, 0.0966796875, 0.10302734375, 0.11181640625, 0.099609375, 0.0771484375, 0.0703125, 0.0361328125, 0.0361328125, 0.0693359375, 0.1171875, 0.1064453125, 0.17822265625, 0.208984375, 0.1484375, 0.1728515625, 0.1240234375, 0.15185546875, 0.25537109375, 0.36181640625, 0.4833984375, 0.5478515625, 0.53271484375, 0.40966796875, 0.2900390625, 0.21435546875, 0.15966796875, 0.21044921875, 0.2373046875, 0.28759765625, 0.3037109375, 0.35498046875, 0.37451171875, 0.34228515625, 0.38818359375, 0.39404296875, 0.47265625, 0.46044921875, 0.39208984375, 0.2724609375, 0.12890625, 0.05078125, 0.0322265625, 0.03173828125, 0.0302734375, 0.03076171875, 0.0302734375, 0.029296875, 0.02783203125, 0.02734375, 0.0244140625, 0.02294921875, 0.0234375, 0.02197265625, 0.021484375, 0.02197265625, 0.01806640625, 0.015625, 0.01611328125, 0.013671875, 0.02587890625, 0.03271484375, 0.04150390625, 0.05712890625, 0.0517578125, 0.0478515625, 0.04150390625, 0.0283203125, 0.02783203125, 0.03125, 0.03076171875, 0.03076171875, 0.0283203125, 0.02490234375, 0.02392578125, 0.02587890625, 0.03173828125, 0.037109375, 0.037109375, 0.03662109375, 0.03076171875, 0.03564453125, 0.06982421875, 0.109375, 0.15771484375, 0.19921875, 0.22216796875, 0.23876953125, 0.24560546875, 0.24951171875, 0.25341796875, 0.25048828125, 0.240234375, 0.185546875, 0.126953125, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.2451171875, 0.32470703125, 0.482421875, 0.4736328125, 0.49755859375, 0.55810546875, 0.48828125, 0.5244140625, 0.47314453125, 0.48291015625, 0.5283203125, 0.49609375, 0.501953125, 0.494140625, 0.48681640625, 0.51611328125, 0.5341796875, 0.50830078125, 0.51513671875, 0.48974609375, 0.478515625, 0.4697265625, 0.48876953125, 0.484375, 0.48095703125, 0.45849609375, 0.4140625, 0.39111328125, 0.35205078125, 0.283203125, 0.19970703125, 0.126953125, 0.07763671875, 0.0986328125, 0.154296875, 0.23193359375, 0.3681640625, 0.474609375, 0.5439453125, 0.591796875, 0.5439453125, 0.4736328125, 0.3837890625, 0.296875, 0.2216796875, 0.19287109375, 0.1826171875, 0.1513671875, 0.11767578125, 0.07470703125, 0.03369140625, 0.021484375, 0.029296875, 0.03466796875, 0.03564453125, 0.0322265625, 0.02685546875, 0.02392578125, 0.01953125, 0.02001953125, 0.0224609375, 0.02294921875, 0.02197265625, 0.0234375, 0.02294921875, 0.02490234375, 0.02685546875, 0.0234375, 0.01904296875, 0.01708984375, 0.01806640625, 0.02001953125, 0.0517578125, 0.08154296875, 0.09912109375, 0.1162109375, 0.09423828125, 0.06494140625, 0.046875, 0.03125, 0.02880859375, 0.03271484375, 0.03271484375, 0.03271484375, 0.03271484375, 0.029296875, 0.03125, 0.0283203125, 0.0234375, 0.02099609375, 0.0185546875, 0.01953125, 0.0185546875, 0.0224609375, 0.0263671875, 0.0224609375, 0.0341796875, 0.06103515625, 0.10498046875, 0.1728515625, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          zcr\n",
       "0  [0.0458984375, 0.0458984375, 0.0458984375, 0.0361328125, 0.0, 0.0, 0.01171875, 0.0400390625, 0.0576171875, 0.0576171875, 0.0458984375, 0.017578125, 0.0126953125, 0.0126953125, 0.0126953125, 0.0361328125, 0.0234375, 0.11376953125, 0.203125, 0.32568359375, 0.349609375, 0.34716796875, 0.2763671875, 0.203125, 0.2275390625, 0.15673828125, 0.18115234375, 0.1435546875, 0.11083984375, 0.1220703125, 0.1396484375, 0.1298828125, 0.1376953125, 0.166015625, 0.1640625, 0.22314453125, 0.302734375, 0.37890625, 0.373046875, 0.36279296875, 0.38134765625, 0.4150390625, 0.43896484375, 0.42822265625, 0.35986328125, 0.244140625, 0.20556640625, 0.14599609375, 0.09423828125, 0.04833984375, 0.01318359375, 0.01513671875, 0.01904296875, 0.02294921875, 0.025390625, 0.0263671875, 0.025390625, 0.0224609375, 0.01953125, 0.02197265625, 0.02001953125, 0.02197265625, 0.0224609375, 0.033203125, 0.0419921875, 0.0625, 0.0849609375, 0.0888671875, 0.0947265625, 0.07861328125, 0.05712890625, 0.04248046875, 0.03759765625, 0.0400390625, 0.04541015625, 0.046875, 0.041015625, 0.03564453125, 0.03271484375, 0.029296875, 0.03466796875, 0.03955078125, 0.03955078125, 0.0419921875, 0.03564453125, 0.0302734375, 0.03076171875, 0.02880859375, 0.02734375, 0.05126953125, 0.11767578125, 0.17822265625, 0.22998046875, 0.259765625, 0.23828125, 0.21630859375, 0.18505859375, 0.12841796875, 0.08154296875, 0.04345703125, ...]                \n",
       "1  [0.0, 0.0, 0.0, 0.03515625, 0.03515625, 0.03515625, 0.03515625, 0.0, 0.0, 0.0322265625, 0.068359375, 0.1474609375, 0.21826171875, 0.2763671875, 0.2529296875, 0.185546875, 0.138671875, 0.095703125, 0.1845703125, 0.197265625, 0.1845703125, 0.19921875, 0.16064453125, 0.27099609375, 0.3408203125, 0.30322265625, 0.24072265625, 0.10546875, 0.0244140625, 0.0146484375, 0.0146484375, 0.02734375, 0.0390625, 0.1044921875, 0.1669921875, 0.181640625, 0.2568359375, 0.33154296875, 0.3671875, 0.46875, 0.515625, 0.42724609375, 0.3935546875, 0.3212890625, 0.23193359375, 0.216796875, 0.19140625, 0.1396484375, 0.1005859375, 0.056640625, 0.02685546875, 0.03173828125, 0.03759765625, 0.04150390625, 0.04052734375, 0.0380859375, 0.037109375, 0.03515625, 0.0361328125, 0.03466796875, 0.02880859375, 0.021484375, 0.01708984375, 0.0224609375, 0.029296875, 0.05078125, 0.10302734375, 0.1455078125, 0.16943359375, 0.169921875, 0.13037109375, 0.0859375, 0.060546875, 0.04833984375, 0.04248046875, 0.04150390625, 0.03857421875, 0.033203125, 0.0283203125, 0.0263671875, 0.02880859375, 0.0302734375, 0.03271484375, 0.0341796875, 0.03515625, 0.0380859375, 0.0380859375, 0.037109375, 0.03662109375, 0.0322265625, 0.03173828125, 0.037109375, 0.0625, 0.12646484375, 0.20361328125, 0.2666015625, 0.2939453125, 0.271484375, 0.19140625, 0.12109375, ...]                                                                                \n",
       "2  [0.0126953125, 0.0126953125, 0.0126953125, 0.0, 0.0, 0.0, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.01171875, 0.0, 0.0, 0.01171875, 0.048828125, 0.16259765625, 0.24560546875, 0.361328125, 0.42578125, 0.43115234375, 0.439453125, 0.39697265625, 0.31396484375, 0.2275390625, 0.140625, 0.06201171875, 0.04931640625, 0.0263671875, 0.0302734375, 0.0302734375, 0.03271484375, 0.029296875, 0.0283203125, 0.0283203125, 0.02783203125, 0.0263671875, 0.02490234375, 0.02392578125, 0.02294921875, 0.0224609375, 0.021484375, 0.01708984375, 0.01318359375, 0.009765625, 0.009765625, 0.01171875, 0.03515625, 0.06005859375, 0.07763671875, 0.0869140625, 0.07373046875, 0.052734375, 0.037109375, 0.03125, 0.02880859375, 0.03125, 0.033203125, 0.03369140625, 0.0322265625, 0.02978515625, 0.0283203125, 0.03173828125, 0.03466796875, 0.03759765625, 0.03759765625, 0.0361328125, 0.04833984375, 0.08740234375, 0.14111328125, 0.18896484375, 0.22119140625, 0.240234375, 0.2431640625, 0.24853515625, 0.2568359375, 0.25146484375, 0.2509765625, 0.24560546875, 0.1982421875, 0.1435546875, ...]                                                                                                                                                                                        \n",
       "3  [0.0234375, 0.0234375, 0.095703125, 0.0966796875, 0.1337890625, 0.146484375, 0.0966796875, 0.10302734375, 0.11181640625, 0.099609375, 0.0771484375, 0.0703125, 0.0361328125, 0.0361328125, 0.0693359375, 0.1171875, 0.1064453125, 0.17822265625, 0.208984375, 0.1484375, 0.1728515625, 0.1240234375, 0.15185546875, 0.25537109375, 0.36181640625, 0.4833984375, 0.5478515625, 0.53271484375, 0.40966796875, 0.2900390625, 0.21435546875, 0.15966796875, 0.21044921875, 0.2373046875, 0.28759765625, 0.3037109375, 0.35498046875, 0.37451171875, 0.34228515625, 0.38818359375, 0.39404296875, 0.47265625, 0.46044921875, 0.39208984375, 0.2724609375, 0.12890625, 0.05078125, 0.0322265625, 0.03173828125, 0.0302734375, 0.03076171875, 0.0302734375, 0.029296875, 0.02783203125, 0.02734375, 0.0244140625, 0.02294921875, 0.0234375, 0.02197265625, 0.021484375, 0.02197265625, 0.01806640625, 0.015625, 0.01611328125, 0.013671875, 0.02587890625, 0.03271484375, 0.04150390625, 0.05712890625, 0.0517578125, 0.0478515625, 0.04150390625, 0.0283203125, 0.02783203125, 0.03125, 0.03076171875, 0.03076171875, 0.0283203125, 0.02490234375, 0.02392578125, 0.02587890625, 0.03173828125, 0.037109375, 0.037109375, 0.03662109375, 0.03076171875, 0.03564453125, 0.06982421875, 0.109375, 0.15771484375, 0.19921875, 0.22216796875, 0.23876953125, 0.24560546875, 0.24951171875, 0.25341796875, 0.25048828125, 0.240234375, 0.185546875, 0.126953125, ...]\n",
       "4  [0.2451171875, 0.32470703125, 0.482421875, 0.4736328125, 0.49755859375, 0.55810546875, 0.48828125, 0.5244140625, 0.47314453125, 0.48291015625, 0.5283203125, 0.49609375, 0.501953125, 0.494140625, 0.48681640625, 0.51611328125, 0.5341796875, 0.50830078125, 0.51513671875, 0.48974609375, 0.478515625, 0.4697265625, 0.48876953125, 0.484375, 0.48095703125, 0.45849609375, 0.4140625, 0.39111328125, 0.35205078125, 0.283203125, 0.19970703125, 0.126953125, 0.07763671875, 0.0986328125, 0.154296875, 0.23193359375, 0.3681640625, 0.474609375, 0.5439453125, 0.591796875, 0.5439453125, 0.4736328125, 0.3837890625, 0.296875, 0.2216796875, 0.19287109375, 0.1826171875, 0.1513671875, 0.11767578125, 0.07470703125, 0.03369140625, 0.021484375, 0.029296875, 0.03466796875, 0.03564453125, 0.0322265625, 0.02685546875, 0.02392578125, 0.01953125, 0.02001953125, 0.0224609375, 0.02294921875, 0.02197265625, 0.0234375, 0.02294921875, 0.02490234375, 0.02685546875, 0.0234375, 0.01904296875, 0.01708984375, 0.01806640625, 0.02001953125, 0.0517578125, 0.08154296875, 0.09912109375, 0.1162109375, 0.09423828125, 0.06494140625, 0.046875, 0.03125, 0.02880859375, 0.03271484375, 0.03271484375, 0.03271484375, 0.03271484375, 0.029296875, 0.03125, 0.0283203125, 0.0234375, 0.02099609375, 0.0185546875, 0.01953125, 0.0185546875, 0.0224609375, 0.0263671875, 0.0224609375, 0.0341796875, 0.06103515625, 0.10498046875, 0.1728515625, ...]   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ITERATE OVER ALL AUDIO FILES AND EXTRACT LOG MEL SPECTROGRAM MEAN VALUES INTO DF FOR MODELING \n",
    "df4 = pd.DataFrame(columns=['zcr'])\n",
    "\n",
    "counter=0\n",
    "\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=3,sr=44100,offset=0.5)\n",
    "    \n",
    "    #get the mel-scaled spectrogram (ransform both the y-axis (frequency) to log scale, and the “color” axis (amplitude) to Decibels, which is kinda the log scale of amplitudes.)\n",
    "   #spectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128,fmax=8000) \n",
    "    #db_spec = librosa.power_to_db(spectrogram)\n",
    "    #temporally average spectrogram\n",
    "   # log_spectrogram = np.mean(db_spec, axis = 0)\n",
    "        \n",
    "    # Mel-frequency cepstral coefficients (MFCCs)\n",
    "    #mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "   # mfcc=np.mean(mfcc,axis=0)\n",
    "    \n",
    "    # compute chroma energy (pertains to 12 different pitch classes)\n",
    "   # chroma = librosa.feature.chroma_stft(y=X, sr=sample_rate)\n",
    "    #chroma = np.mean(chroma, axis = 0)\n",
    "\n",
    "    # compute spectral contrast\n",
    "   # contrast = librosa.feature.spectral_contrast(y=X, sr=sample_rate)\n",
    "    ##contrast = np.mean(contrast, axis= 0)\n",
    "\n",
    "    # compute zero-crossing-rate (zcr:the zcr is the rate of sign changes along a signal i.e.m the rate at \n",
    "      #which the signal changes from positive to negative or back - separation of voiced andunvoiced speech.)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=X)\n",
    "    zcr = np.mean(zcr, axis= 0)\n",
    "    \n",
    "    df4.loc[counter] = [zcr]\n",
    "    counter=counter+1   \n",
    "\n",
    "print(len(df4))\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    for index1, row1 in df1.iterrows():\n",
    "        if index==index1:\n",
    "            np.append(df['mel_spectrogram'].iloc[index],df1['mfcc'].iloc[index1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    for index1, row1 in df4.iterrows():\n",
    "        if index==index1:\n",
    "            np.append(df['mel_spectrogram'].iloc[index],df4['zcr'].iloc[index1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN ARRAY INTO LIST AND JOIN WITH AUDIO_DF TO GET CORRESPONDING EMOTION LABELS\n",
    "df_combined = pd.concat([audio_df,pd.DataFrame(df['mel_spectrogram'].values.tolist())],axis=1)\n",
    "df_combined = df_combined.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP PATH COLUMN FOR MODELING\n",
    "df_combined.drop(columns='path',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>actor</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>-70.670029</td>\n",
       "      <td>-70.670029</td>\n",
       "      <td>-70.670029</td>\n",
       "      <td>-70.670029</td>\n",
       "      <td>-70.670029</td>\n",
       "      <td>-70.670029</td>\n",
       "      <td>-70.670029</td>\n",
       "      <td>...</td>\n",
       "      <td>-68.066002</td>\n",
       "      <td>-67.823112</td>\n",
       "      <td>-67.432503</td>\n",
       "      <td>-68.307655</td>\n",
       "      <td>-69.391975</td>\n",
       "      <td>-70.005867</td>\n",
       "      <td>-69.689926</td>\n",
       "      <td>-69.448280</td>\n",
       "      <td>-70.223541</td>\n",
       "      <td>-70.668686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>-68.248024</td>\n",
       "      <td>-68.248024</td>\n",
       "      <td>-68.248024</td>\n",
       "      <td>-68.248024</td>\n",
       "      <td>-68.248024</td>\n",
       "      <td>-68.248024</td>\n",
       "      <td>-68.248024</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.481239</td>\n",
       "      <td>-64.914200</td>\n",
       "      <td>-64.897858</td>\n",
       "      <td>-65.435928</td>\n",
       "      <td>-65.597946</td>\n",
       "      <td>-65.811577</td>\n",
       "      <td>-66.184433</td>\n",
       "      <td>-66.435219</td>\n",
       "      <td>-66.681755</td>\n",
       "      <td>-66.831551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>-67.809029</td>\n",
       "      <td>-67.809029</td>\n",
       "      <td>-67.809029</td>\n",
       "      <td>-67.809029</td>\n",
       "      <td>-67.809029</td>\n",
       "      <td>-67.809029</td>\n",
       "      <td>-67.809029</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.496956</td>\n",
       "      <td>-66.004318</td>\n",
       "      <td>-67.040688</td>\n",
       "      <td>-67.305740</td>\n",
       "      <td>-67.364838</td>\n",
       "      <td>-67.651810</td>\n",
       "      <td>-67.803123</td>\n",
       "      <td>-67.809029</td>\n",
       "      <td>-67.809029</td>\n",
       "      <td>-67.809029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>-69.634232</td>\n",
       "      <td>-69.634232</td>\n",
       "      <td>-69.634232</td>\n",
       "      <td>-69.634232</td>\n",
       "      <td>-69.634232</td>\n",
       "      <td>-69.634232</td>\n",
       "      <td>-69.634232</td>\n",
       "      <td>...</td>\n",
       "      <td>-68.144333</td>\n",
       "      <td>-69.438469</td>\n",
       "      <td>-69.443871</td>\n",
       "      <td>-69.445557</td>\n",
       "      <td>-69.282272</td>\n",
       "      <td>-69.280853</td>\n",
       "      <td>-69.626266</td>\n",
       "      <td>-69.491142</td>\n",
       "      <td>-69.634232</td>\n",
       "      <td>-69.634232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "      <td>1</td>\n",
       "      <td>-70.884789</td>\n",
       "      <td>-70.865654</td>\n",
       "      <td>-70.864937</td>\n",
       "      <td>-70.884789</td>\n",
       "      <td>-70.444595</td>\n",
       "      <td>-70.051346</td>\n",
       "      <td>-70.290291</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.121502</td>\n",
       "      <td>-58.398827</td>\n",
       "      <td>-59.137722</td>\n",
       "      <td>-59.750404</td>\n",
       "      <td>-60.642406</td>\n",
       "      <td>-59.983891</td>\n",
       "      <td>-57.985138</td>\n",
       "      <td>-56.684620</td>\n",
       "      <td>-56.078949</td>\n",
       "      <td>-56.611732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  emotion  actor          0          1          2          3  \\\n",
       "0  male   neutral  1     -70.670029 -70.670029 -70.670029 -70.670029   \n",
       "1  male   neutral  1     -68.248024 -68.248024 -68.248024 -68.248024   \n",
       "2  male   neutral  1     -67.809029 -67.809029 -67.809029 -67.809029   \n",
       "3  male   neutral  1     -69.634232 -69.634232 -69.634232 -69.634232   \n",
       "4  male   calm     1     -70.884789 -70.865654 -70.864937 -70.884789   \n",
       "\n",
       "           4          5          6  ...        249        250        251  \\\n",
       "0 -70.670029 -70.670029 -70.670029  ... -68.066002 -67.823112 -67.432503   \n",
       "1 -68.248024 -68.248024 -68.248024  ... -64.481239 -64.914200 -64.897858   \n",
       "2 -67.809029 -67.809029 -67.809029  ... -65.496956 -66.004318 -67.040688   \n",
       "3 -69.634232 -69.634232 -69.634232  ... -68.144333 -69.438469 -69.443871   \n",
       "4 -70.444595 -70.051346 -70.290291  ... -58.121502 -58.398827 -59.137722   \n",
       "\n",
       "         252        253        254        255        256        257        258  \n",
       "0 -68.307655 -69.391975 -70.005867 -69.689926 -69.448280 -70.223541 -70.668686  \n",
       "1 -65.435928 -65.597946 -65.811577 -66.184433 -66.435219 -66.681755 -66.831551  \n",
       "2 -67.305740 -67.364838 -67.651810 -67.803123 -67.809029 -67.809029 -67.809029  \n",
       "3 -69.445557 -69.282272 -69.280853 -69.626266 -69.491142 -69.634232 -69.634232  \n",
       "4 -59.750404 -60.642406 -59.983891 -57.985138 -56.684620 -56.078949 -56.611732  \n",
       "\n",
       "[5 rows x 262 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK TOP 5 ROWS\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT DATA\n",
    "train,test = train_test_split(df_combined, test_size=0.2, random_state=0,\n",
    "                               stratify=df_combined[['emotion','gender','actor']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809, 259)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.iloc[:, 3:]\n",
    "y_train = train.iloc[:,:2].drop(columns=['gender'])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203, 259)\n"
     ]
    }
   ],
   "source": [
    "X_test = test.iloc[:,3:]\n",
    "y_test = test.iloc[:,:2].drop(columns=['gender'])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA standard deviation (z score)\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN DATA INTO ARRAYS FOR KERAS\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# ONE HOT ENCODE THE TARGET\n",
    "# CNN REQUIRES INPUT AND OUTPUT ARE NUMBERS\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "lb = LabelEncoder()\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_test = to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'calm' 'fear' 'happy' 'neutral' 'sad']\n"
     ]
    }
   ],
   "source": [
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(809, 259)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(809, 259, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESHAPE DATA TO INCLUDE 3D TENSOR \n",
    "X_train = X_train[:,:,np.newaxis]\n",
    "X_test = X_test[:,:,np.newaxis]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying different parameters for the CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-32-nodes-0-dense-1653489694\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 250, 32)           352       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 41, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1312)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 7878      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,230\n",
      "Trainable params: 8,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 5s 77ms/step - loss: 1.6013 - accuracy: 0.3164 - val_loss: 1.5025 - val_accuracy: 0.3793\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.4292 - accuracy: 0.3918 - val_loss: 1.4240 - val_accuracy: 0.3941\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 1.3436 - accuracy: 0.4203 - val_loss: 1.3668 - val_accuracy: 0.4138\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.2835 - accuracy: 0.4574 - val_loss: 1.3484 - val_accuracy: 0.4236\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.2441 - accuracy: 0.4574 - val_loss: 1.3423 - val_accuracy: 0.4335\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.2036 - accuracy: 0.4920 - val_loss: 1.3215 - val_accuracy: 0.4286\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.1800 - accuracy: 0.5068 - val_loss: 1.3082 - val_accuracy: 0.4680\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.1430 - accuracy: 0.5328 - val_loss: 1.3390 - val_accuracy: 0.4483\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.1212 - accuracy: 0.5365 - val_loss: 1.3229 - val_accuracy: 0.4631\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0852 - accuracy: 0.5513 - val_loss: 1.3146 - val_accuracy: 0.4729\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0680 - accuracy: 0.5612 - val_loss: 1.2969 - val_accuracy: 0.4729\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0659 - accuracy: 0.5661 - val_loss: 1.3265 - val_accuracy: 0.4581\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 1.0462 - accuracy: 0.5884 - val_loss: 1.2631 - val_accuracy: 0.5074\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 1.0074 - accuracy: 0.5995 - val_loss: 1.3088 - val_accuracy: 0.4877\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9898 - accuracy: 0.5983 - val_loss: 1.2933 - val_accuracy: 0.4877\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9734 - accuracy: 0.6143 - val_loss: 1.2462 - val_accuracy: 0.4828\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.9492 - accuracy: 0.6180 - val_loss: 1.2446 - val_accuracy: 0.4877\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9587 - accuracy: 0.6180 - val_loss: 1.2544 - val_accuracy: 0.5123\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9069 - accuracy: 0.6341 - val_loss: 1.2542 - val_accuracy: 0.4975\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9267 - accuracy: 0.6267 - val_loss: 1.2368 - val_accuracy: 0.5025\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8693 - accuracy: 0.6638 - val_loss: 1.2277 - val_accuracy: 0.4975\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.8651 - accuracy: 0.6465 - val_loss: 1.2645 - val_accuracy: 0.5222\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8472 - accuracy: 0.6638 - val_loss: 1.2342 - val_accuracy: 0.5074\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8221 - accuracy: 0.6737 - val_loss: 1.2522 - val_accuracy: 0.5271\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8309 - accuracy: 0.6823 - val_loss: 1.2245 - val_accuracy: 0.5468\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7996 - accuracy: 0.6972 - val_loss: 1.2129 - val_accuracy: 0.5320\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7836 - accuracy: 0.7070 - val_loss: 1.2661 - val_accuracy: 0.5369\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8043 - accuracy: 0.6823 - val_loss: 1.2755 - val_accuracy: 0.4877\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7848 - accuracy: 0.6873 - val_loss: 1.1975 - val_accuracy: 0.5222\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7475 - accuracy: 0.7219 - val_loss: 1.2236 - val_accuracy: 0.5271\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7352 - accuracy: 0.7132 - val_loss: 1.2108 - val_accuracy: 0.5468\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7201 - accuracy: 0.7305 - val_loss: 1.2875 - val_accuracy: 0.5567\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7243 - accuracy: 0.7244 - val_loss: 1.2668 - val_accuracy: 0.5025\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7113 - accuracy: 0.7256 - val_loss: 1.2211 - val_accuracy: 0.5320\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7107 - accuracy: 0.7157 - val_loss: 1.2277 - val_accuracy: 0.5222\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7002 - accuracy: 0.7305 - val_loss: 1.2104 - val_accuracy: 0.5468\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6798 - accuracy: 0.7417 - val_loss: 1.2249 - val_accuracy: 0.5271\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6581 - accuracy: 0.7676 - val_loss: 1.2310 - val_accuracy: 0.5172\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6605 - accuracy: 0.7553 - val_loss: 1.2222 - val_accuracy: 0.5320\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6515 - accuracy: 0.7491 - val_loss: 1.2456 - val_accuracy: 0.5222\n",
      "2-conv-32-nodes-0-dense-1653489721\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 250, 32)           352       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 41, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 41, 32)            10272     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 1158      \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 11,782\n",
      "Trainable params: 11,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 6s 58ms/step - loss: 1.6901 - accuracy: 0.2250 - val_loss: 1.5718 - val_accuracy: 0.2660\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.4896 - accuracy: 0.3214 - val_loss: 1.4816 - val_accuracy: 0.3054\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.4307 - accuracy: 0.3239 - val_loss: 1.4431 - val_accuracy: 0.3892\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.3764 - accuracy: 0.4017 - val_loss: 1.4288 - val_accuracy: 0.3941\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.3147 - accuracy: 0.4351 - val_loss: 1.3554 - val_accuracy: 0.4187\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.2618 - accuracy: 0.4339 - val_loss: 1.3101 - val_accuracy: 0.4532\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 1.2226 - accuracy: 0.4833 - val_loss: 1.3177 - val_accuracy: 0.4483\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1691 - accuracy: 0.4981 - val_loss: 1.2962 - val_accuracy: 0.4926\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.1387 - accuracy: 0.5426 - val_loss: 1.2659 - val_accuracy: 0.4483\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.0919 - accuracy: 0.5476 - val_loss: 1.2633 - val_accuracy: 0.5025\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.0431 - accuracy: 0.5859 - val_loss: 1.2555 - val_accuracy: 0.5172\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.0098 - accuracy: 0.6094 - val_loss: 1.1857 - val_accuracy: 0.5271\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.9610 - accuracy: 0.6242 - val_loss: 1.2131 - val_accuracy: 0.5222\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.9425 - accuracy: 0.6378 - val_loss: 1.2270 - val_accuracy: 0.5271\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.9233 - accuracy: 0.6279 - val_loss: 1.2628 - val_accuracy: 0.4975\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.9042 - accuracy: 0.6477 - val_loss: 1.1739 - val_accuracy: 0.5616\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.8454 - accuracy: 0.6922 - val_loss: 1.1600 - val_accuracy: 0.5714\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.8182 - accuracy: 0.6947 - val_loss: 1.1748 - val_accuracy: 0.5764\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.7723 - accuracy: 0.7145 - val_loss: 1.1744 - val_accuracy: 0.5862\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.7620 - accuracy: 0.7157 - val_loss: 1.1481 - val_accuracy: 0.5714\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.7011 - accuracy: 0.7553 - val_loss: 1.1607 - val_accuracy: 0.5567\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.6982 - accuracy: 0.7429 - val_loss: 1.1671 - val_accuracy: 0.6010\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6639 - accuracy: 0.7689 - val_loss: 1.1304 - val_accuracy: 0.6010\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.6358 - accuracy: 0.7614 - val_loss: 1.2617 - val_accuracy: 0.5074\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6435 - accuracy: 0.7775 - val_loss: 1.2098 - val_accuracy: 0.6010\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.5847 - accuracy: 0.8059 - val_loss: 1.1675 - val_accuracy: 0.5665\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.5820 - accuracy: 0.7787 - val_loss: 1.1491 - val_accuracy: 0.5862\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.5391 - accuracy: 0.8220 - val_loss: 1.1571 - val_accuracy: 0.5961\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.5407 - accuracy: 0.8121 - val_loss: 1.1673 - val_accuracy: 0.6108\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5112 - accuracy: 0.8146 - val_loss: 1.2014 - val_accuracy: 0.5714\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.4832 - accuracy: 0.8381 - val_loss: 1.1711 - val_accuracy: 0.6010\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4862 - accuracy: 0.8393 - val_loss: 1.1717 - val_accuracy: 0.6355\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4631 - accuracy: 0.8504 - val_loss: 1.2455 - val_accuracy: 0.5665\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.4541 - accuracy: 0.8443 - val_loss: 1.1637 - val_accuracy: 0.6256\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.4036 - accuracy: 0.8875 - val_loss: 1.2221 - val_accuracy: 0.6059\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.4276 - accuracy: 0.8566 - val_loss: 1.2139 - val_accuracy: 0.5764\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4108 - accuracy: 0.8566 - val_loss: 1.2296 - val_accuracy: 0.6010\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.3622 - accuracy: 0.8888 - val_loss: 1.2952 - val_accuracy: 0.5714\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.3604 - accuracy: 0.8900 - val_loss: 1.2176 - val_accuracy: 0.6207\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.3421 - accuracy: 0.8937 - val_loss: 1.2351 - val_accuracy: 0.5911\n",
      "3-conv-32-nodes-0-dense-1653489749\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 250, 32)           352       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 41, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 41, 32)            10272     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 6, 32)             10272     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 1, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,094\n",
      "Trainable params: 21,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 6s 61ms/step - loss: 1.5918 - accuracy: 0.3140 - val_loss: 1.5393 - val_accuracy: 0.3498\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 1.4613 - accuracy: 0.3646 - val_loss: 1.4816 - val_accuracy: 0.3547\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.4215 - accuracy: 0.4005 - val_loss: 1.4633 - val_accuracy: 0.3596\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.3986 - accuracy: 0.3906 - val_loss: 1.4114 - val_accuracy: 0.3744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.3273 - accuracy: 0.4376 - val_loss: 1.3588 - val_accuracy: 0.4286\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.2578 - accuracy: 0.4623 - val_loss: 1.3238 - val_accuracy: 0.4138\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2068 - accuracy: 0.4907 - val_loss: 1.3006 - val_accuracy: 0.4187\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.1615 - accuracy: 0.4944 - val_loss: 1.2578 - val_accuracy: 0.4433\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.1074 - accuracy: 0.5439 - val_loss: 1.2244 - val_accuracy: 0.4926\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.0657 - accuracy: 0.5575 - val_loss: 1.2933 - val_accuracy: 0.4631\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.0320 - accuracy: 0.5723 - val_loss: 1.1691 - val_accuracy: 0.5271\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9618 - accuracy: 0.6119 - val_loss: 1.1800 - val_accuracy: 0.5320\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.8925 - accuracy: 0.6489 - val_loss: 1.1857 - val_accuracy: 0.5172\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.8896 - accuracy: 0.6428 - val_loss: 1.2133 - val_accuracy: 0.5123\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8627 - accuracy: 0.6675 - val_loss: 1.1251 - val_accuracy: 0.5567\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.7666 - accuracy: 0.7169 - val_loss: 1.1339 - val_accuracy: 0.5468\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.7288 - accuracy: 0.7206 - val_loss: 1.2527 - val_accuracy: 0.5025\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.7198 - accuracy: 0.7108 - val_loss: 1.1552 - val_accuracy: 0.5419\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.6311 - accuracy: 0.7590 - val_loss: 1.1621 - val_accuracy: 0.5665\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6582 - accuracy: 0.7503 - val_loss: 1.1002 - val_accuracy: 0.5517\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.5469 - accuracy: 0.8047 - val_loss: 1.0916 - val_accuracy: 0.6010\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.5211 - accuracy: 0.8121 - val_loss: 1.1250 - val_accuracy: 0.5567\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.4769 - accuracy: 0.8331 - val_loss: 1.1574 - val_accuracy: 0.5517\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.4248 - accuracy: 0.8702 - val_loss: 1.1223 - val_accuracy: 0.6158\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.4458 - accuracy: 0.8344 - val_loss: 1.2255 - val_accuracy: 0.5567\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.4498 - accuracy: 0.8319 - val_loss: 1.2386 - val_accuracy: 0.5665\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3359 - accuracy: 0.9011 - val_loss: 1.2834 - val_accuracy: 0.5369\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.3402 - accuracy: 0.8912 - val_loss: 1.2029 - val_accuracy: 0.5961\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3027 - accuracy: 0.9036 - val_loss: 1.2687 - val_accuracy: 0.5862\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2719 - accuracy: 0.9308 - val_loss: 1.3329 - val_accuracy: 0.5714\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.2389 - accuracy: 0.9419 - val_loss: 1.3781 - val_accuracy: 0.5911\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.2244 - accuracy: 0.9468 - val_loss: 1.3453 - val_accuracy: 0.6158\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2192 - accuracy: 0.9407 - val_loss: 1.3266 - val_accuracy: 0.5813\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.1910 - accuracy: 0.9506 - val_loss: 1.3486 - val_accuracy: 0.5665\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.1782 - accuracy: 0.9580 - val_loss: 1.3464 - val_accuracy: 0.6010\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.1520 - accuracy: 0.9679 - val_loss: 1.3980 - val_accuracy: 0.5813\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.1269 - accuracy: 0.9740 - val_loss: 1.4555 - val_accuracy: 0.6207\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.1188 - accuracy: 0.9864 - val_loss: 1.4415 - val_accuracy: 0.5911\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.1111 - accuracy: 0.9802 - val_loss: 1.5128 - val_accuracy: 0.5764\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.0891 - accuracy: 0.9889 - val_loss: 1.4748 - val_accuracy: 0.5961\n",
      "1-conv-64-nodes-0-dense-1653489780\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 250, 64)           704       \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 41, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2624)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 15750     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,454\n",
      "Trainable params: 16,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 6s 64ms/step - loss: 1.5532 - accuracy: 0.3127 - val_loss: 1.4616 - val_accuracy: 0.3399\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 1.3908 - accuracy: 0.3857 - val_loss: 1.3758 - val_accuracy: 0.3941\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.3071 - accuracy: 0.4277 - val_loss: 1.3572 - val_accuracy: 0.4039\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.2434 - accuracy: 0.4611 - val_loss: 1.3814 - val_accuracy: 0.3645\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 1.2128 - accuracy: 0.4858 - val_loss: 1.3485 - val_accuracy: 0.3941\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.1706 - accuracy: 0.4944 - val_loss: 1.3041 - val_accuracy: 0.4483\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.1345 - accuracy: 0.5204 - val_loss: 1.3008 - val_accuracy: 0.4631\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1013 - accuracy: 0.5328 - val_loss: 1.3112 - val_accuracy: 0.4729\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0549 - accuracy: 0.5600 - val_loss: 1.3042 - val_accuracy: 0.4778\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0220 - accuracy: 0.5884 - val_loss: 1.2822 - val_accuracy: 0.5074\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.0207 - accuracy: 0.5810 - val_loss: 1.2682 - val_accuracy: 0.5025\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.0094 - accuracy: 0.5773 - val_loss: 1.2610 - val_accuracy: 0.5172\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.9510 - accuracy: 0.6267 - val_loss: 1.2973 - val_accuracy: 0.4778\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.9485 - accuracy: 0.6020 - val_loss: 1.2305 - val_accuracy: 0.4975\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9054 - accuracy: 0.6465 - val_loss: 1.2405 - val_accuracy: 0.5271\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8791 - accuracy: 0.6502 - val_loss: 1.2708 - val_accuracy: 0.4877\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.8489 - accuracy: 0.6700 - val_loss: 1.3012 - val_accuracy: 0.4975\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.8724 - accuracy: 0.6440 - val_loss: 1.2200 - val_accuracy: 0.5468\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.8291 - accuracy: 0.6761 - val_loss: 1.2493 - val_accuracy: 0.5369\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7979 - accuracy: 0.6885 - val_loss: 1.2492 - val_accuracy: 0.5369\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7976 - accuracy: 0.6922 - val_loss: 1.2435 - val_accuracy: 0.5123\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.7727 - accuracy: 0.6959 - val_loss: 1.2173 - val_accuracy: 0.5419\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.7516 - accuracy: 0.7157 - val_loss: 1.2510 - val_accuracy: 0.5320\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.7265 - accuracy: 0.7318 - val_loss: 1.2240 - val_accuracy: 0.5369\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.7133 - accuracy: 0.7318 - val_loss: 1.2421 - val_accuracy: 0.5567\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6891 - accuracy: 0.7441 - val_loss: 1.2285 - val_accuracy: 0.5271\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6770 - accuracy: 0.7503 - val_loss: 1.2353 - val_accuracy: 0.5419\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6723 - accuracy: 0.7417 - val_loss: 1.2342 - val_accuracy: 0.5222\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.6501 - accuracy: 0.7590 - val_loss: 1.3300 - val_accuracy: 0.5172\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6308 - accuracy: 0.7837 - val_loss: 1.2224 - val_accuracy: 0.5517\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6064 - accuracy: 0.7960 - val_loss: 1.2580 - val_accuracy: 0.5419\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.5982 - accuracy: 0.7812 - val_loss: 1.2487 - val_accuracy: 0.5172\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5776 - accuracy: 0.7960 - val_loss: 1.2605 - val_accuracy: 0.5714\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.5749 - accuracy: 0.7998 - val_loss: 1.2968 - val_accuracy: 0.5419\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.5754 - accuracy: 0.7837 - val_loss: 1.3462 - val_accuracy: 0.4729\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5755 - accuracy: 0.7948 - val_loss: 1.2803 - val_accuracy: 0.5517\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5335 - accuracy: 0.8084 - val_loss: 1.2513 - val_accuracy: 0.5369\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.5474 - accuracy: 0.8109 - val_loss: 1.2773 - val_accuracy: 0.5369\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4974 - accuracy: 0.8282 - val_loss: 1.2987 - val_accuracy: 0.5567\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5059 - accuracy: 0.8294 - val_loss: 1.3041 - val_accuracy: 0.5074\n",
      "2-conv-64-nodes-0-dense-1653489808\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_7 (Conv1D)           (None, 250, 64)           704       \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 41, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 41, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 6, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 2310      \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,038\n",
      "Trainable params: 44,038\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 5s 86ms/step - loss: 1.5829 - accuracy: 0.3276 - val_loss: 1.5011 - val_accuracy: 0.3793\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 1.4382 - accuracy: 0.3857 - val_loss: 1.4286 - val_accuracy: 0.3744\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.3488 - accuracy: 0.4190 - val_loss: 1.3903 - val_accuracy: 0.3842\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.2961 - accuracy: 0.4561 - val_loss: 1.3631 - val_accuracy: 0.4236\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 1.2134 - accuracy: 0.4981 - val_loss: 1.3158 - val_accuracy: 0.3941\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 1.1481 - accuracy: 0.5241 - val_loss: 1.3115 - val_accuracy: 0.4729\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.0807 - accuracy: 0.5760 - val_loss: 1.2873 - val_accuracy: 0.4433\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 1.0014 - accuracy: 0.6007 - val_loss: 1.2279 - val_accuracy: 0.5369\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.9329 - accuracy: 0.6502 - val_loss: 1.1998 - val_accuracy: 0.5074\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.8909 - accuracy: 0.6638 - val_loss: 1.1914 - val_accuracy: 0.5567\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.8276 - accuracy: 0.6712 - val_loss: 1.1211 - val_accuracy: 0.5665\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7574 - accuracy: 0.7182 - val_loss: 1.1163 - val_accuracy: 0.6010\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7000 - accuracy: 0.7417 - val_loss: 1.1244 - val_accuracy: 0.5911\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6812 - accuracy: 0.7478 - val_loss: 1.1230 - val_accuracy: 0.5813\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6491 - accuracy: 0.7713 - val_loss: 1.0980 - val_accuracy: 0.5764\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.5782 - accuracy: 0.8059 - val_loss: 1.2154 - val_accuracy: 0.5813\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.5453 - accuracy: 0.8121 - val_loss: 1.1053 - val_accuracy: 0.5813\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.5046 - accuracy: 0.8269 - val_loss: 1.1744 - val_accuracy: 0.5764\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.4974 - accuracy: 0.8381 - val_loss: 1.1191 - val_accuracy: 0.5961\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.4702 - accuracy: 0.8269 - val_loss: 1.1452 - val_accuracy: 0.5813\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 31ms/step - loss: 0.4463 - accuracy: 0.8467 - val_loss: 1.1559 - val_accuracy: 0.5911\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.3707 - accuracy: 0.8850 - val_loss: 1.0805 - val_accuracy: 0.6207\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.3462 - accuracy: 0.8937 - val_loss: 1.0994 - val_accuracy: 0.6207\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.3334 - accuracy: 0.9023 - val_loss: 1.1151 - val_accuracy: 0.6256\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.2916 - accuracy: 0.9110 - val_loss: 1.1201 - val_accuracy: 0.6453\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.2879 - accuracy: 0.9073 - val_loss: 1.1493 - val_accuracy: 0.6059\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.2191 - accuracy: 0.9481 - val_loss: 1.0950 - val_accuracy: 0.6256\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.1929 - accuracy: 0.9642 - val_loss: 1.1633 - val_accuracy: 0.6207\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1682 - accuracy: 0.9740 - val_loss: 1.1165 - val_accuracy: 0.6502\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1485 - accuracy: 0.9815 - val_loss: 1.1418 - val_accuracy: 0.6207\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.1325 - accuracy: 0.9839 - val_loss: 1.1587 - val_accuracy: 0.6404\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.1229 - accuracy: 0.9889 - val_loss: 1.2261 - val_accuracy: 0.6453\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1095 - accuracy: 0.9913 - val_loss: 1.2335 - val_accuracy: 0.6158\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1197 - accuracy: 0.9802 - val_loss: 1.2654 - val_accuracy: 0.6158\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.1117 - accuracy: 0.9913 - val_loss: 1.3397 - val_accuracy: 0.6059\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0964 - accuracy: 0.9889 - val_loss: 1.2591 - val_accuracy: 0.6650\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0799 - accuracy: 0.9938 - val_loss: 1.2762 - val_accuracy: 0.6305\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0694 - accuracy: 0.9951 - val_loss: 1.3126 - val_accuracy: 0.6256\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0568 - accuracy: 0.9975 - val_loss: 1.3254 - val_accuracy: 0.6453\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0604 - accuracy: 0.9963 - val_loss: 1.3293 - val_accuracy: 0.6404\n",
      "3-conv-64-nodes-0-dense-1653489847\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_9 (Conv1D)           (None, 250, 64)           704       \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 41, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 41, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 6, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 6, 64)             41024     \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83,142\n",
      "Trainable params: 83,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 7s 78ms/step - loss: 1.5751 - accuracy: 0.2658 - val_loss: 1.5178 - val_accuracy: 0.2709\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4749 - accuracy: 0.2979 - val_loss: 1.4881 - val_accuracy: 0.2857\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4301 - accuracy: 0.3239 - val_loss: 1.4396 - val_accuracy: 0.3596\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3809 - accuracy: 0.4215 - val_loss: 1.4026 - val_accuracy: 0.3842\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.2897 - accuracy: 0.4413 - val_loss: 1.3584 - val_accuracy: 0.4089\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.2555 - accuracy: 0.4574 - val_loss: 1.2824 - val_accuracy: 0.4187\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.1273 - accuracy: 0.5130 - val_loss: 1.2256 - val_accuracy: 0.4877\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.0439 - accuracy: 0.5698 - val_loss: 1.1679 - val_accuracy: 0.5320\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9328 - accuracy: 0.6304 - val_loss: 1.2088 - val_accuracy: 0.5123\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.8595 - accuracy: 0.6576 - val_loss: 1.1395 - val_accuracy: 0.5468\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.7825 - accuracy: 0.6934 - val_loss: 1.0753 - val_accuracy: 0.5813\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.6763 - accuracy: 0.7330 - val_loss: 1.0926 - val_accuracy: 0.5911\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6015 - accuracy: 0.7590 - val_loss: 1.0728 - val_accuracy: 0.6010\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.5277 - accuracy: 0.7998 - val_loss: 1.0465 - val_accuracy: 0.5961\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.4610 - accuracy: 0.8418 - val_loss: 1.1140 - val_accuracy: 0.6108\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.4322 - accuracy: 0.8443 - val_loss: 1.0987 - val_accuracy: 0.5862\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.3324 - accuracy: 0.8974 - val_loss: 1.1446 - val_accuracy: 0.5911\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.2952 - accuracy: 0.9023 - val_loss: 1.2683 - val_accuracy: 0.6207\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.2829 - accuracy: 0.9061 - val_loss: 1.2227 - val_accuracy: 0.6305\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.2657 - accuracy: 0.9085 - val_loss: 1.4180 - val_accuracy: 0.5665\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1987 - accuracy: 0.9481 - val_loss: 1.2997 - val_accuracy: 0.6256\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1572 - accuracy: 0.9555 - val_loss: 1.2167 - val_accuracy: 0.6108\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1320 - accuracy: 0.9703 - val_loss: 1.4253 - val_accuracy: 0.6207\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.1570 - accuracy: 0.9518 - val_loss: 1.2602 - val_accuracy: 0.6305\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0815 - accuracy: 0.9876 - val_loss: 1.4103 - val_accuracy: 0.6158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0662 - accuracy: 0.9839 - val_loss: 1.3786 - val_accuracy: 0.6453\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0567 - accuracy: 0.9876 - val_loss: 1.3982 - val_accuracy: 0.6453\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0478 - accuracy: 0.9913 - val_loss: 1.5202 - val_accuracy: 0.6207\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0705 - accuracy: 0.9765 - val_loss: 1.5454 - val_accuracy: 0.6158\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0486 - accuracy: 0.9889 - val_loss: 1.5199 - val_accuracy: 0.6207\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0845 - accuracy: 0.9740 - val_loss: 1.5052 - val_accuracy: 0.6158\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0434 - accuracy: 0.9938 - val_loss: 1.5943 - val_accuracy: 0.6404\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0359 - accuracy: 0.9926 - val_loss: 1.5198 - val_accuracy: 0.6552\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0234 - accuracy: 0.9951 - val_loss: 1.6065 - val_accuracy: 0.6305\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 1.6332 - val_accuracy: 0.6502\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 1.6358 - val_accuracy: 0.6355\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 1.6561 - val_accuracy: 0.6305\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.6899 - val_accuracy: 0.6256\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 1.7054 - val_accuracy: 0.6059\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 1.7159 - val_accuracy: 0.6158\n",
      "1-conv-128-nodes-0-dense-1653489893\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 41, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 5248)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 31494     \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,902\n",
      "Trainable params: 32,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 5s 48ms/step - loss: 1.5206 - accuracy: 0.3263 - val_loss: 1.4476 - val_accuracy: 0.3941\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 1.3702 - accuracy: 0.4067 - val_loss: 1.3511 - val_accuracy: 0.3990\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.2793 - accuracy: 0.4302 - val_loss: 1.3221 - val_accuracy: 0.4433\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 1.2190 - accuracy: 0.4796 - val_loss: 1.3979 - val_accuracy: 0.4138\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.2040 - accuracy: 0.4944 - val_loss: 1.3291 - val_accuracy: 0.4384\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 1.1551 - accuracy: 0.5130 - val_loss: 1.3136 - val_accuracy: 0.4433\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 1.1067 - accuracy: 0.5328 - val_loss: 1.2923 - val_accuracy: 0.4877\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.0821 - accuracy: 0.5315 - val_loss: 1.2713 - val_accuracy: 0.5172\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.0417 - accuracy: 0.5748 - val_loss: 1.2597 - val_accuracy: 0.4631\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 1.0254 - accuracy: 0.5785 - val_loss: 1.2825 - val_accuracy: 0.4631\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.9529 - accuracy: 0.6143 - val_loss: 1.2709 - val_accuracy: 0.5074\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.9217 - accuracy: 0.6230 - val_loss: 1.2475 - val_accuracy: 0.5271\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.8939 - accuracy: 0.6489 - val_loss: 1.2596 - val_accuracy: 0.4778\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.8698 - accuracy: 0.6415 - val_loss: 1.2445 - val_accuracy: 0.5222\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.8258 - accuracy: 0.6576 - val_loss: 1.2865 - val_accuracy: 0.4729\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.8101 - accuracy: 0.6836 - val_loss: 1.2418 - val_accuracy: 0.5320\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.7533 - accuracy: 0.7157 - val_loss: 1.2127 - val_accuracy: 0.5172\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.7404 - accuracy: 0.7157 - val_loss: 1.2337 - val_accuracy: 0.5320\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.7290 - accuracy: 0.7182 - val_loss: 1.2105 - val_accuracy: 0.5369\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.7316 - accuracy: 0.7083 - val_loss: 1.2895 - val_accuracy: 0.5567\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6863 - accuracy: 0.7342 - val_loss: 1.2178 - val_accuracy: 0.5172\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6424 - accuracy: 0.7639 - val_loss: 1.2335 - val_accuracy: 0.5517\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6311 - accuracy: 0.7763 - val_loss: 1.2274 - val_accuracy: 0.5567\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.5983 - accuracy: 0.7800 - val_loss: 1.2385 - val_accuracy: 0.5517\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.5897 - accuracy: 0.7948 - val_loss: 1.2613 - val_accuracy: 0.5369\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.5736 - accuracy: 0.7960 - val_loss: 1.2635 - val_accuracy: 0.5419\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.5477 - accuracy: 0.7960 - val_loss: 1.2579 - val_accuracy: 0.5517\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.5504 - accuracy: 0.7985 - val_loss: 1.2972 - val_accuracy: 0.5468\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.5189 - accuracy: 0.8245 - val_loss: 1.2813 - val_accuracy: 0.5468\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.5179 - accuracy: 0.8183 - val_loss: 1.2946 - val_accuracy: 0.5320\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.4992 - accuracy: 0.8344 - val_loss: 1.2895 - val_accuracy: 0.5271\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.4620 - accuracy: 0.8517 - val_loss: 1.2859 - val_accuracy: 0.5369\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.4489 - accuracy: 0.8517 - val_loss: 1.3370 - val_accuracy: 0.5320\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.4336 - accuracy: 0.8628 - val_loss: 1.3293 - val_accuracy: 0.5025\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.4615 - accuracy: 0.8331 - val_loss: 1.3535 - val_accuracy: 0.5320\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.4343 - accuracy: 0.8517 - val_loss: 1.3889 - val_accuracy: 0.5468\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.4016 - accuracy: 0.8702 - val_loss: 1.3753 - val_accuracy: 0.5320\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.3870 - accuracy: 0.8863 - val_loss: 1.3835 - val_accuracy: 0.5271\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.4106 - accuracy: 0.8566 - val_loss: 1.4275 - val_accuracy: 0.5665\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.3760 - accuracy: 0.8739 - val_loss: 1.4000 - val_accuracy: 0.5369\n",
      "2-conv-128-nodes-0-dense-1653489927\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_13 (Conv1D)          (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 41, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 6, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 768)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 4614      \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,990\n",
      "Trainable params: 169,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 7s 90ms/step - loss: 1.5439 - accuracy: 0.3066 - val_loss: 1.5054 - val_accuracy: 0.3103\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.4208 - accuracy: 0.3375 - val_loss: 1.4190 - val_accuracy: 0.3744\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.3210 - accuracy: 0.4227 - val_loss: 1.3959 - val_accuracy: 0.3842\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2279 - accuracy: 0.4536 - val_loss: 1.2882 - val_accuracy: 0.4335\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.1526 - accuracy: 0.5179 - val_loss: 1.3471 - val_accuracy: 0.3990\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 1.0578 - accuracy: 0.5488 - val_loss: 1.2039 - val_accuracy: 0.4828\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.9814 - accuracy: 0.6230 - val_loss: 1.1608 - val_accuracy: 0.5468\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.8676 - accuracy: 0.6638 - val_loss: 1.1744 - val_accuracy: 0.5419\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.7587 - accuracy: 0.7182 - val_loss: 1.1030 - val_accuracy: 0.5862\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 0.6997 - accuracy: 0.7367 - val_loss: 1.1433 - val_accuracy: 0.5616\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.6460 - accuracy: 0.7627 - val_loss: 1.1805 - val_accuracy: 0.5665\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.5407 - accuracy: 0.8245 - val_loss: 1.1865 - val_accuracy: 0.5567\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.4770 - accuracy: 0.8319 - val_loss: 1.1076 - val_accuracy: 0.6453\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.3746 - accuracy: 0.8863 - val_loss: 1.1713 - val_accuracy: 0.6010\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.3583 - accuracy: 0.8801 - val_loss: 1.0958 - val_accuracy: 0.6059\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.2906 - accuracy: 0.9184 - val_loss: 1.1273 - val_accuracy: 0.6010\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.2317 - accuracy: 0.9407 - val_loss: 1.1482 - val_accuracy: 0.6158\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1734 - accuracy: 0.9716 - val_loss: 1.1834 - val_accuracy: 0.5961\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1504 - accuracy: 0.9728 - val_loss: 1.2120 - val_accuracy: 0.6158\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1130 - accuracy: 0.9864 - val_loss: 1.2344 - val_accuracy: 0.6207\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.0910 - accuracy: 0.9901 - val_loss: 1.2497 - val_accuracy: 0.6355\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.0951 - accuracy: 0.9815 - val_loss: 1.3818 - val_accuracy: 0.6108\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.0714 - accuracy: 0.9926 - val_loss: 1.3436 - val_accuracy: 0.6010\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 1.3354 - val_accuracy: 0.6207\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 1.4995 - val_accuracy: 0.6059\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.0397 - accuracy: 0.9988 - val_loss: 1.4301 - val_accuracy: 0.6207\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.4448 - val_accuracy: 0.5961\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.5324 - val_accuracy: 0.6158\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.4720 - val_accuracy: 0.6207\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.5246 - val_accuracy: 0.6158\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.5466 - val_accuracy: 0.5961\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.5326 - val_accuracy: 0.6059\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.5514 - val_accuracy: 0.6207\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.5930 - val_accuracy: 0.6158\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.5902 - val_accuracy: 0.6108\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.6106 - val_accuracy: 0.6108\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.6286 - val_accuracy: 0.6059\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.6414 - val_accuracy: 0.6207\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.6700 - val_accuracy: 0.6010\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.6718 - val_accuracy: 0.6207\n",
      "3-conv-128-nodes-0-dense-1653490001\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " conv1d_15 (Conv1D)          (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 41, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPoolin  (None, 6, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 6, 128)            163968    \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (None, 1, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330,118\n",
      "Trainable params: 330,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 8s 126ms/step - loss: 1.5574 - accuracy: 0.3214 - val_loss: 1.5080 - val_accuracy: 0.3596\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 1.4464 - accuracy: 0.3733 - val_loss: 1.4460 - val_accuracy: 0.3202\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 1.3877 - accuracy: 0.4042 - val_loss: 1.3535 - val_accuracy: 0.3744\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 1.2538 - accuracy: 0.4648 - val_loss: 1.3466 - val_accuracy: 0.4236\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 1.1994 - accuracy: 0.4944 - val_loss: 1.2956 - val_accuracy: 0.4286\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 1.0776 - accuracy: 0.5290 - val_loss: 1.3018 - val_accuracy: 0.4581\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 1.0125 - accuracy: 0.5859 - val_loss: 1.1304 - val_accuracy: 0.5468\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.8282 - accuracy: 0.6761 - val_loss: 1.1921 - val_accuracy: 0.5468\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.7285 - accuracy: 0.7095 - val_loss: 1.1814 - val_accuracy: 0.5320\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.6844 - accuracy: 0.7206 - val_loss: 1.1062 - val_accuracy: 0.5714\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.5550 - accuracy: 0.7911 - val_loss: 1.0703 - val_accuracy: 0.6207\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.4291 - accuracy: 0.8529 - val_loss: 1.0928 - val_accuracy: 0.5862\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.3753 - accuracy: 0.8616 - val_loss: 1.1647 - val_accuracy: 0.5961\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.2854 - accuracy: 0.9023 - val_loss: 1.1824 - val_accuracy: 0.6502\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.1905 - accuracy: 0.9580 - val_loss: 1.2225 - val_accuracy: 0.6355\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.1142 - accuracy: 0.9728 - val_loss: 1.2207 - val_accuracy: 0.6700\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.0840 - accuracy: 0.9852 - val_loss: 1.2258 - val_accuracy: 0.6847\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.0606 - accuracy: 0.9926 - val_loss: 1.2614 - val_accuracy: 0.6256\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.0353 - accuracy: 0.9975 - val_loss: 1.3429 - val_accuracy: 0.6552\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.0313 - accuracy: 0.9963 - val_loss: 1.3749 - val_accuracy: 0.6700\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.3749 - val_accuracy: 0.6847\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3835 - val_accuracy: 0.6700\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.3788 - val_accuracy: 0.6847\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 2s 88ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.4502 - val_accuracy: 0.6552\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.4899 - val_accuracy: 0.6552\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.5080 - val_accuracy: 0.6404\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.5082 - val_accuracy: 0.6502\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 2s 73ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.5136 - val_accuracy: 0.6749\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5248 - val_accuracy: 0.6650\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.5369 - val_accuracy: 0.6601\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.6700\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5728 - val_accuracy: 0.6601\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5825 - val_accuracy: 0.6601\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6000 - val_accuracy: 0.6650\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6024 - val_accuracy: 0.6502\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6283 - val_accuracy: 0.6650\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6318 - val_accuracy: 0.6601\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6405 - val_accuracy: 0.6700\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6398 - val_accuracy: 0.6650\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6625 - val_accuracy: 0.6552\n",
      "1-conv-32-nodes-1-dense-1653490088\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_18 (Conv1D)          (None, 250, 32)           352       \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, 41, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 1312)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                42016     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 6)                 198       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,566\n",
      "Trainable params: 42,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 7s 75ms/step - loss: 1.5487 - accuracy: 0.3325 - val_loss: 1.4720 - val_accuracy: 0.3941\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.3733 - accuracy: 0.4153 - val_loss: 1.3865 - val_accuracy: 0.4286\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.2992 - accuracy: 0.4512 - val_loss: 1.3519 - val_accuracy: 0.3990\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.3010 - accuracy: 0.4227 - val_loss: 1.3299 - val_accuracy: 0.4532\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 1.2088 - accuracy: 0.4845 - val_loss: 1.3227 - val_accuracy: 0.3842\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.1425 - accuracy: 0.5167 - val_loss: 1.2936 - val_accuracy: 0.4433\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 1.0927 - accuracy: 0.5352 - val_loss: 1.2558 - val_accuracy: 0.4729\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.0487 - accuracy: 0.5674 - val_loss: 1.2584 - val_accuracy: 0.4926\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.0310 - accuracy: 0.5723 - val_loss: 1.2770 - val_accuracy: 0.4778\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.9946 - accuracy: 0.5995 - val_loss: 1.2735 - val_accuracy: 0.4877\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 1.0171 - accuracy: 0.5909 - val_loss: 1.2350 - val_accuracy: 0.5172\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.9265 - accuracy: 0.6267 - val_loss: 1.2176 - val_accuracy: 0.5172\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.8733 - accuracy: 0.6564 - val_loss: 1.2677 - val_accuracy: 0.4975\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.8605 - accuracy: 0.6613 - val_loss: 1.2335 - val_accuracy: 0.4877\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8282 - accuracy: 0.6774 - val_loss: 1.2250 - val_accuracy: 0.5025\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7785 - accuracy: 0.6848 - val_loss: 1.1803 - val_accuracy: 0.5419\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.7481 - accuracy: 0.7120 - val_loss: 1.2080 - val_accuracy: 0.5517\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.7520 - accuracy: 0.6947 - val_loss: 1.1689 - val_accuracy: 0.5123\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6973 - accuracy: 0.7379 - val_loss: 1.1926 - val_accuracy: 0.5271\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6448 - accuracy: 0.7404 - val_loss: 1.1891 - val_accuracy: 0.5616\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6192 - accuracy: 0.7602 - val_loss: 1.2205 - val_accuracy: 0.5714\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5735 - accuracy: 0.7837 - val_loss: 1.1848 - val_accuracy: 0.5567\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5498 - accuracy: 0.7923 - val_loss: 1.2299 - val_accuracy: 0.5665\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5179 - accuracy: 0.8195 - val_loss: 1.2301 - val_accuracy: 0.5468\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4972 - accuracy: 0.8269 - val_loss: 1.2274 - val_accuracy: 0.5419\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.4822 - accuracy: 0.8158 - val_loss: 1.2149 - val_accuracy: 0.5567\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4397 - accuracy: 0.8554 - val_loss: 1.2098 - val_accuracy: 0.5665\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4413 - accuracy: 0.8492 - val_loss: 1.1968 - val_accuracy: 0.5862\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4102 - accuracy: 0.8529 - val_loss: 1.3049 - val_accuracy: 0.5517\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3842 - accuracy: 0.8628 - val_loss: 1.2487 - val_accuracy: 0.5567\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3685 - accuracy: 0.8826 - val_loss: 1.3555 - val_accuracy: 0.5862\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3611 - accuracy: 0.8764 - val_loss: 1.2776 - val_accuracy: 0.5517\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3203 - accuracy: 0.9048 - val_loss: 1.3421 - val_accuracy: 0.5764\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.3215 - accuracy: 0.8949 - val_loss: 1.3523 - val_accuracy: 0.5665\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.2900 - accuracy: 0.9159 - val_loss: 1.3065 - val_accuracy: 0.5764\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.2663 - accuracy: 0.9221 - val_loss: 1.3231 - val_accuracy: 0.5665\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2568 - accuracy: 0.9345 - val_loss: 1.3369 - val_accuracy: 0.5665\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.2858 - accuracy: 0.8999 - val_loss: 1.3686 - val_accuracy: 0.5665\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.4310 - accuracy: 0.8368 - val_loss: 1.4271 - val_accuracy: 0.5665\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2508 - accuracy: 0.9221 - val_loss: 1.3758 - val_accuracy: 0.5714\n",
      "2-conv-32-nodes-1-dense-1653490117\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_19 (Conv1D)          (None, 250, 32)           352       \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (None, 41, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 41, 32)            10272     \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,998\n",
      "Trainable params: 16,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 7s 79ms/step - loss: 1.6914 - accuracy: 0.3337 - val_loss: 1.5920 - val_accuracy: 0.3498\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 1.4864 - accuracy: 0.3782 - val_loss: 1.4633 - val_accuracy: 0.3448\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.4054 - accuracy: 0.4042 - val_loss: 1.4440 - val_accuracy: 0.3596\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 1.3543 - accuracy: 0.4302 - val_loss: 1.3854 - val_accuracy: 0.3842\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 1.3163 - accuracy: 0.4462 - val_loss: 1.3752 - val_accuracy: 0.4433\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.2843 - accuracy: 0.4734 - val_loss: 1.3075 - val_accuracy: 0.4384\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.2272 - accuracy: 0.4623 - val_loss: 1.3297 - val_accuracy: 0.4384\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.1806 - accuracy: 0.4895 - val_loss: 1.2315 - val_accuracy: 0.4778\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.1396 - accuracy: 0.5080 - val_loss: 1.2930 - val_accuracy: 0.4138\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1159 - accuracy: 0.5241 - val_loss: 1.2023 - val_accuracy: 0.4680\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.0654 - accuracy: 0.5340 - val_loss: 1.2077 - val_accuracy: 0.4926\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.0301 - accuracy: 0.5822 - val_loss: 1.2238 - val_accuracy: 0.4631\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.9959 - accuracy: 0.5810 - val_loss: 1.2041 - val_accuracy: 0.4877\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.9355 - accuracy: 0.6316 - val_loss: 1.0870 - val_accuracy: 0.5665\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.8899 - accuracy: 0.6514 - val_loss: 1.1090 - val_accuracy: 0.5764\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.8604 - accuracy: 0.6502 - val_loss: 1.1695 - val_accuracy: 0.5172\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.8834 - accuracy: 0.6378 - val_loss: 1.1464 - val_accuracy: 0.5567\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.7863 - accuracy: 0.7033 - val_loss: 1.0976 - val_accuracy: 0.5764\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7344 - accuracy: 0.7120 - val_loss: 1.1286 - val_accuracy: 0.5517\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.7857 - accuracy: 0.7021 - val_loss: 1.0494 - val_accuracy: 0.6010\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6950 - accuracy: 0.7454 - val_loss: 1.0750 - val_accuracy: 0.6059\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6798 - accuracy: 0.7379 - val_loss: 1.1202 - val_accuracy: 0.5419\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6289 - accuracy: 0.7676 - val_loss: 1.0513 - val_accuracy: 0.5764\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.5861 - accuracy: 0.7936 - val_loss: 1.0929 - val_accuracy: 0.5616\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6260 - accuracy: 0.7528 - val_loss: 1.1032 - val_accuracy: 0.5862\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.5666 - accuracy: 0.7985 - val_loss: 1.1348 - val_accuracy: 0.5616\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.5481 - accuracy: 0.8035 - val_loss: 1.0425 - val_accuracy: 0.6108\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.4959 - accuracy: 0.8294 - val_loss: 1.1319 - val_accuracy: 0.5714\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.4828 - accuracy: 0.8208 - val_loss: 1.0802 - val_accuracy: 0.6158\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.4567 - accuracy: 0.8282 - val_loss: 1.0536 - val_accuracy: 0.6158\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.4532 - accuracy: 0.8356 - val_loss: 1.1063 - val_accuracy: 0.6010\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.4000 - accuracy: 0.8616 - val_loss: 1.1014 - val_accuracy: 0.5862\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.3642 - accuracy: 0.8801 - val_loss: 1.1074 - val_accuracy: 0.5911\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3293 - accuracy: 0.8962 - val_loss: 1.1054 - val_accuracy: 0.6305\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3193 - accuracy: 0.9159 - val_loss: 1.1715 - val_accuracy: 0.6010\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.3022 - accuracy: 0.9110 - val_loss: 1.1662 - val_accuracy: 0.6158\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.2817 - accuracy: 0.9159 - val_loss: 1.1705 - val_accuracy: 0.5862\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2492 - accuracy: 0.9283 - val_loss: 1.1374 - val_accuracy: 0.6305\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2707 - accuracy: 0.9197 - val_loss: 1.1842 - val_accuracy: 0.6158\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.2147 - accuracy: 0.9468 - val_loss: 1.1728 - val_accuracy: 0.6059\n",
      "3-conv-32-nodes-1-dense-1653490150\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_21 (Conv1D)          (None, 250, 32)           352       \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 41, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 41, 32)            10272     \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 6, 32)             10272     \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,150\n",
      "Trainable params: 22,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 8s 88ms/step - loss: 1.6764 - accuracy: 0.2967 - val_loss: 1.5489 - val_accuracy: 0.2759\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 1.4967 - accuracy: 0.3214 - val_loss: 1.5050 - val_accuracy: 0.3448\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 1.4568 - accuracy: 0.3770 - val_loss: 1.4627 - val_accuracy: 0.3645\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.4391 - accuracy: 0.3832 - val_loss: 1.4335 - val_accuracy: 0.3547\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.4014 - accuracy: 0.4141 - val_loss: 1.4074 - val_accuracy: 0.3645\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3358 - accuracy: 0.4339 - val_loss: 1.4168 - val_accuracy: 0.3744\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.2822 - accuracy: 0.4623 - val_loss: 1.3167 - val_accuracy: 0.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 1.2300 - accuracy: 0.4944 - val_loss: 1.2913 - val_accuracy: 0.4433\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.1541 - accuracy: 0.5340 - val_loss: 1.2572 - val_accuracy: 0.4532\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.0792 - accuracy: 0.5698 - val_loss: 1.2557 - val_accuracy: 0.4532\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.0580 - accuracy: 0.5661 - val_loss: 1.2617 - val_accuracy: 0.4631\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.0098 - accuracy: 0.5871 - val_loss: 1.1796 - val_accuracy: 0.5567\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.9495 - accuracy: 0.6218 - val_loss: 1.2134 - val_accuracy: 0.4729\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.9238 - accuracy: 0.6391 - val_loss: 1.2217 - val_accuracy: 0.5271\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.8704 - accuracy: 0.6613 - val_loss: 1.2168 - val_accuracy: 0.4975\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.7823 - accuracy: 0.7058 - val_loss: 1.2757 - val_accuracy: 0.4926\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.8089 - accuracy: 0.6663 - val_loss: 1.1583 - val_accuracy: 0.5567\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7209 - accuracy: 0.7367 - val_loss: 1.1754 - val_accuracy: 0.5320\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.6490 - accuracy: 0.7614 - val_loss: 1.3109 - val_accuracy: 0.4680\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.6090 - accuracy: 0.7812 - val_loss: 1.2198 - val_accuracy: 0.5419\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.5399 - accuracy: 0.8059 - val_loss: 1.1517 - val_accuracy: 0.5764\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5843 - accuracy: 0.7849 - val_loss: 1.2018 - val_accuracy: 0.5517\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.5173 - accuracy: 0.8171 - val_loss: 1.2584 - val_accuracy: 0.5468\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.4894 - accuracy: 0.8096 - val_loss: 1.2332 - val_accuracy: 0.5665\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.4283 - accuracy: 0.8492 - val_loss: 1.1654 - val_accuracy: 0.6256\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.3898 - accuracy: 0.8591 - val_loss: 1.1867 - val_accuracy: 0.5764\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.4009 - accuracy: 0.8603 - val_loss: 1.2555 - val_accuracy: 0.5764\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3413 - accuracy: 0.8912 - val_loss: 1.3298 - val_accuracy: 0.5616\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.3379 - accuracy: 0.8776 - val_loss: 1.2442 - val_accuracy: 0.5911\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.2881 - accuracy: 0.9036 - val_loss: 1.2630 - val_accuracy: 0.5813\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.2456 - accuracy: 0.9246 - val_loss: 1.2580 - val_accuracy: 0.6059\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1860 - accuracy: 0.9567 - val_loss: 1.2425 - val_accuracy: 0.6502\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1980 - accuracy: 0.9629 - val_loss: 1.2817 - val_accuracy: 0.6256\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.1517 - accuracy: 0.9679 - val_loss: 1.3923 - val_accuracy: 0.5961\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1623 - accuracy: 0.9543 - val_loss: 1.4251 - val_accuracy: 0.5862\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.1709 - accuracy: 0.9506 - val_loss: 1.3638 - val_accuracy: 0.6059\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1374 - accuracy: 0.9654 - val_loss: 1.3709 - val_accuracy: 0.6059\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.1408 - accuracy: 0.9679 - val_loss: 1.4197 - val_accuracy: 0.6158\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.1370 - accuracy: 0.9580 - val_loss: 1.4842 - val_accuracy: 0.6108\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1129 - accuracy: 0.9740 - val_loss: 1.5056 - val_accuracy: 0.6256\n",
      "1-conv-64-nodes-1-dense-1653490191\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_24 (Conv1D)          (None, 250, 64)           704       \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPoolin  (None, 41, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 2624)              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                168000    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,094\n",
      "Trainable params: 169,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 7s 83ms/step - loss: 1.5296 - accuracy: 0.3164 - val_loss: 1.4621 - val_accuracy: 0.3645\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.3593 - accuracy: 0.4363 - val_loss: 1.3273 - val_accuracy: 0.4286\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.2591 - accuracy: 0.4598 - val_loss: 1.3704 - val_accuracy: 0.3941\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.1804 - accuracy: 0.5056 - val_loss: 1.3198 - val_accuracy: 0.4631\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.1201 - accuracy: 0.5167 - val_loss: 1.3036 - val_accuracy: 0.4581\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.0514 - accuracy: 0.5513 - val_loss: 1.2916 - val_accuracy: 0.4975\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.9731 - accuracy: 0.5933 - val_loss: 1.3699 - val_accuracy: 0.4532\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.9411 - accuracy: 0.6156 - val_loss: 1.2222 - val_accuracy: 0.5172\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.8873 - accuracy: 0.6341 - val_loss: 1.2566 - val_accuracy: 0.5172\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.8172 - accuracy: 0.6675 - val_loss: 1.3072 - val_accuracy: 0.4975\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7752 - accuracy: 0.6860 - val_loss: 1.2505 - val_accuracy: 0.5320\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.7355 - accuracy: 0.6947 - val_loss: 1.2344 - val_accuracy: 0.5172\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7072 - accuracy: 0.7194 - val_loss: 1.1958 - val_accuracy: 0.5271\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.6568 - accuracy: 0.7268 - val_loss: 1.2624 - val_accuracy: 0.5074\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6446 - accuracy: 0.7478 - val_loss: 1.2450 - val_accuracy: 0.5419\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.5722 - accuracy: 0.7738 - val_loss: 1.2288 - val_accuracy: 0.5320\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.5556 - accuracy: 0.7886 - val_loss: 1.3458 - val_accuracy: 0.5320\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.5284 - accuracy: 0.7973 - val_loss: 1.3870 - val_accuracy: 0.5123\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.5309 - accuracy: 0.7985 - val_loss: 1.2676 - val_accuracy: 0.5271\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.4261 - accuracy: 0.8529 - val_loss: 1.2575 - val_accuracy: 0.5517\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.3661 - accuracy: 0.8714 - val_loss: 1.2434 - val_accuracy: 0.5320\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.3411 - accuracy: 0.8937 - val_loss: 1.2517 - val_accuracy: 0.5567\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.3501 - accuracy: 0.8813 - val_loss: 1.3844 - val_accuracy: 0.5369\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.3361 - accuracy: 0.8888 - val_loss: 1.3235 - val_accuracy: 0.5567\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.3171 - accuracy: 0.8925 - val_loss: 1.3300 - val_accuracy: 0.5567\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.3020 - accuracy: 0.8937 - val_loss: 1.2932 - val_accuracy: 0.5320\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.2534 - accuracy: 0.9234 - val_loss: 1.3673 - val_accuracy: 0.5419\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2193 - accuracy: 0.9357 - val_loss: 1.4113 - val_accuracy: 0.5517\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.2155 - accuracy: 0.9246 - val_loss: 1.3826 - val_accuracy: 0.5567\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2101 - accuracy: 0.9333 - val_loss: 1.3902 - val_accuracy: 0.5419\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2086 - accuracy: 0.9221 - val_loss: 1.4270 - val_accuracy: 0.5665\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.1631 - accuracy: 0.9567 - val_loss: 1.4709 - val_accuracy: 0.5616\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.1552 - accuracy: 0.9642 - val_loss: 1.4428 - val_accuracy: 0.5616\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1576 - accuracy: 0.9567 - val_loss: 1.4531 - val_accuracy: 0.5764\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.1205 - accuracy: 0.9691 - val_loss: 1.4812 - val_accuracy: 0.5813\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.1206 - accuracy: 0.9642 - val_loss: 1.4651 - val_accuracy: 0.5813\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.1051 - accuracy: 0.9815 - val_loss: 1.5220 - val_accuracy: 0.5813\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0986 - accuracy: 0.9753 - val_loss: 1.5001 - val_accuracy: 0.5911\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0892 - accuracy: 0.9802 - val_loss: 1.5516 - val_accuracy: 0.5961\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.0761 - accuracy: 0.9864 - val_loss: 1.5979 - val_accuracy: 0.5961\n",
      "2-conv-64-nodes-1-dense-1653490225\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_25 (Conv1D)          (None, 250, 64)           704       \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (None, 41, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 41, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_26 (MaxPoolin  (None, 6, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,758\n",
      "Trainable params: 66,758\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 7s 91ms/step - loss: 1.5801 - accuracy: 0.3028 - val_loss: 1.4839 - val_accuracy: 0.3695\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.4209 - accuracy: 0.3832 - val_loss: 1.4648 - val_accuracy: 0.3596\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.3366 - accuracy: 0.4166 - val_loss: 1.4936 - val_accuracy: 0.3645\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.2822 - accuracy: 0.4499 - val_loss: 1.3056 - val_accuracy: 0.3990\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.2032 - accuracy: 0.4932 - val_loss: 1.2970 - val_accuracy: 0.4926\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.1370 - accuracy: 0.5266 - val_loss: 1.2295 - val_accuracy: 0.4877\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.0266 - accuracy: 0.5958 - val_loss: 1.2399 - val_accuracy: 0.4778\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.9915 - accuracy: 0.6094 - val_loss: 1.1473 - val_accuracy: 0.5517\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.8361 - accuracy: 0.6836 - val_loss: 1.1403 - val_accuracy: 0.5369\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.8101 - accuracy: 0.6836 - val_loss: 1.1088 - val_accuracy: 0.5419\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.7766 - accuracy: 0.6836 - val_loss: 1.1904 - val_accuracy: 0.5419\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6780 - accuracy: 0.7355 - val_loss: 1.0398 - val_accuracy: 0.5911\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.5982 - accuracy: 0.7824 - val_loss: 1.0733 - val_accuracy: 0.5813\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.5209 - accuracy: 0.8195 - val_loss: 1.0680 - val_accuracy: 0.6256\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.4551 - accuracy: 0.8430 - val_loss: 0.9797 - val_accuracy: 0.6108\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3902 - accuracy: 0.8690 - val_loss: 1.0868 - val_accuracy: 0.5961\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.4258 - accuracy: 0.8517 - val_loss: 1.1630 - val_accuracy: 0.5862\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.3656 - accuracy: 0.8739 - val_loss: 1.1360 - val_accuracy: 0.5961\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.2924 - accuracy: 0.9159 - val_loss: 1.1242 - val_accuracy: 0.6059\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.3548 - accuracy: 0.8665 - val_loss: 1.1690 - val_accuracy: 0.6158\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.2501 - accuracy: 0.9320 - val_loss: 1.2155 - val_accuracy: 0.5911\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1982 - accuracy: 0.9468 - val_loss: 1.1498 - val_accuracy: 0.6355\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1767 - accuracy: 0.9555 - val_loss: 1.2379 - val_accuracy: 0.6404\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1278 - accuracy: 0.9740 - val_loss: 1.2281 - val_accuracy: 0.6158\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1024 - accuracy: 0.9827 - val_loss: 1.2096 - val_accuracy: 0.6059\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0976 - accuracy: 0.9790 - val_loss: 1.2772 - val_accuracy: 0.6305\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0947 - accuracy: 0.9802 - val_loss: 1.3342 - val_accuracy: 0.6404\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0713 - accuracy: 0.9889 - val_loss: 1.3575 - val_accuracy: 0.6404\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0536 - accuracy: 0.9963 - val_loss: 1.3509 - val_accuracy: 0.6305\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0453 - accuracy: 0.9963 - val_loss: 1.4026 - val_accuracy: 0.6305\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0383 - accuracy: 0.9988 - val_loss: 1.3839 - val_accuracy: 0.6059\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0327 - accuracy: 0.9975 - val_loss: 1.4670 - val_accuracy: 0.6108\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0294 - accuracy: 0.9988 - val_loss: 1.4462 - val_accuracy: 0.6158\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0286 - accuracy: 0.9975 - val_loss: 1.5093 - val_accuracy: 0.5911\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 1.5519 - val_accuracy: 0.6108\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.5140 - val_accuracy: 0.6207\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.5626 - val_accuracy: 0.6207\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.5666 - val_accuracy: 0.6010\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.5662 - val_accuracy: 0.6108\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.5788 - val_accuracy: 0.5961\n",
      "3-conv-64-nodes-1-dense-1653490267\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_27 (Conv1D)          (None, 250, 64)           704       \n",
      "                                                                 \n",
      " max_pooling1d_27 (MaxPoolin  (None, 41, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_28 (Conv1D)          (None, 41, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPoolin  (None, 6, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 6, 64)             41024     \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87,302\n",
      "Trainable params: 87,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 6s 76ms/step - loss: 1.6034 - accuracy: 0.2781 - val_loss: 1.5091 - val_accuracy: 0.2759\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4797 - accuracy: 0.2843 - val_loss: 1.5054 - val_accuracy: 0.2660\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 1.4448 - accuracy: 0.3239 - val_loss: 1.4654 - val_accuracy: 0.2906\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4078 - accuracy: 0.3004 - val_loss: 1.4292 - val_accuracy: 0.3153\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3508 - accuracy: 0.3634 - val_loss: 1.3853 - val_accuracy: 0.3547\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.2932 - accuracy: 0.4240 - val_loss: 1.3371 - val_accuracy: 0.3892\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.1820 - accuracy: 0.4994 - val_loss: 1.3507 - val_accuracy: 0.4236\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.1840 - accuracy: 0.4833 - val_loss: 1.2628 - val_accuracy: 0.4680\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 1.0579 - accuracy: 0.5587 - val_loss: 1.2966 - val_accuracy: 0.4778\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.0401 - accuracy: 0.5760 - val_loss: 1.1608 - val_accuracy: 0.5665\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.9037 - accuracy: 0.6415 - val_loss: 1.2864 - val_accuracy: 0.5025\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.8687 - accuracy: 0.6403 - val_loss: 1.1562 - val_accuracy: 0.5320\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7540 - accuracy: 0.6885 - val_loss: 1.1533 - val_accuracy: 0.5764\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.8339 - accuracy: 0.6836 - val_loss: 1.0971 - val_accuracy: 0.5665\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.6307 - accuracy: 0.7602 - val_loss: 1.0713 - val_accuracy: 0.6010\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.5080 - accuracy: 0.8146 - val_loss: 1.2620 - val_accuracy: 0.5369\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.4465 - accuracy: 0.8356 - val_loss: 1.2119 - val_accuracy: 0.5665\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3773 - accuracy: 0.8801 - val_loss: 1.2794 - val_accuracy: 0.5764\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.3656 - accuracy: 0.8665 - val_loss: 1.2294 - val_accuracy: 0.5764\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.2633 - accuracy: 0.9184 - val_loss: 1.2331 - val_accuracy: 0.5911\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.2343 - accuracy: 0.9209 - val_loss: 1.2865 - val_accuracy: 0.6256\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.2500 - accuracy: 0.9110 - val_loss: 1.4138 - val_accuracy: 0.6059\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1729 - accuracy: 0.9456 - val_loss: 1.3135 - val_accuracy: 0.6305\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.2065 - accuracy: 0.9197 - val_loss: 1.4860 - val_accuracy: 0.6108\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.1678 - accuracy: 0.9419 - val_loss: 1.4000 - val_accuracy: 0.5764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.0945 - accuracy: 0.9740 - val_loss: 1.4837 - val_accuracy: 0.6256\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0600 - accuracy: 0.9864 - val_loss: 1.5201 - val_accuracy: 0.6502\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0463 - accuracy: 0.9864 - val_loss: 1.5674 - val_accuracy: 0.6108\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0573 - accuracy: 0.9839 - val_loss: 1.6535 - val_accuracy: 0.6108\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0499 - accuracy: 0.9815 - val_loss: 1.5817 - val_accuracy: 0.6158\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0367 - accuracy: 0.9926 - val_loss: 1.6428 - val_accuracy: 0.6404\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0308 - accuracy: 0.9926 - val_loss: 1.8051 - val_accuracy: 0.6207\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0360 - accuracy: 0.9913 - val_loss: 1.6821 - val_accuracy: 0.6355\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 1.7089 - val_accuracy: 0.6404\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 1.7693 - val_accuracy: 0.6355\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 1.7845 - val_accuracy: 0.6305\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 1.8827 - val_accuracy: 0.6305\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 1.8430 - val_accuracy: 0.6453\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0097 - accuracy: 0.9951 - val_loss: 1.9076 - val_accuracy: 0.6355\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0085 - accuracy: 0.9951 - val_loss: 1.9102 - val_accuracy: 0.6404\n",
      "1-conv-128-nodes-1-dense-1653490310\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_30 (Conv1D)          (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 41, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 5248)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               671872    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 674,054\n",
      "Trainable params: 674,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 6s 64ms/step - loss: 1.5020 - accuracy: 0.3337 - val_loss: 1.4638 - val_accuracy: 0.3448\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.3134 - accuracy: 0.4277 - val_loss: 1.3816 - val_accuracy: 0.4286\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.2268 - accuracy: 0.4524 - val_loss: 1.3463 - val_accuracy: 0.4384\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 1.1398 - accuracy: 0.5117 - val_loss: 1.2420 - val_accuracy: 0.4926\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.0416 - accuracy: 0.5575 - val_loss: 1.2516 - val_accuracy: 0.5025\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.9297 - accuracy: 0.6168 - val_loss: 1.2452 - val_accuracy: 0.5074\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.8449 - accuracy: 0.6551 - val_loss: 1.2279 - val_accuracy: 0.5320\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.8214 - accuracy: 0.6601 - val_loss: 1.1682 - val_accuracy: 0.5517\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.7260 - accuracy: 0.7182 - val_loss: 1.2834 - val_accuracy: 0.5074\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6629 - accuracy: 0.7120 - val_loss: 1.2937 - val_accuracy: 0.5222\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.5816 - accuracy: 0.7787 - val_loss: 1.2805 - val_accuracy: 0.5419\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.5156 - accuracy: 0.8072 - val_loss: 1.2461 - val_accuracy: 0.5320\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.4767 - accuracy: 0.8121 - val_loss: 1.3287 - val_accuracy: 0.5320\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.4004 - accuracy: 0.8492 - val_loss: 1.1870 - val_accuracy: 0.5714\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.3290 - accuracy: 0.8850 - val_loss: 1.2083 - val_accuracy: 0.5468\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.2858 - accuracy: 0.9023 - val_loss: 1.3144 - val_accuracy: 0.5468\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.2672 - accuracy: 0.9122 - val_loss: 1.3769 - val_accuracy: 0.5567\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.2491 - accuracy: 0.9221 - val_loss: 1.3726 - val_accuracy: 0.5813\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.2018 - accuracy: 0.9333 - val_loss: 1.3265 - val_accuracy: 0.5616\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1809 - accuracy: 0.9382 - val_loss: 1.3374 - val_accuracy: 0.6108\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.1708 - accuracy: 0.9468 - val_loss: 1.3568 - val_accuracy: 0.5961\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1247 - accuracy: 0.9642 - val_loss: 1.3155 - val_accuracy: 0.6305\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.1035 - accuracy: 0.9703 - val_loss: 1.3977 - val_accuracy: 0.6059\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0992 - accuracy: 0.9728 - val_loss: 1.3956 - val_accuracy: 0.6207\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1128 - accuracy: 0.9642 - val_loss: 1.3869 - val_accuracy: 0.6108\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0762 - accuracy: 0.9827 - val_loss: 1.5037 - val_accuracy: 0.6010\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0636 - accuracy: 0.9802 - val_loss: 1.5809 - val_accuracy: 0.6355\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.1165 - accuracy: 0.9617 - val_loss: 1.4933 - val_accuracy: 0.6404\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0842 - accuracy: 0.9790 - val_loss: 1.6229 - val_accuracy: 0.5862\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0511 - accuracy: 0.9889 - val_loss: 1.5536 - val_accuracy: 0.6108\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0435 - accuracy: 0.9864 - val_loss: 1.5347 - val_accuracy: 0.5862\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0293 - accuracy: 0.9938 - val_loss: 1.5761 - val_accuracy: 0.5862\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0234 - accuracy: 0.9963 - val_loss: 1.6144 - val_accuracy: 0.6059\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0213 - accuracy: 0.9951 - val_loss: 1.6062 - val_accuracy: 0.6010\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 1.6186 - val_accuracy: 0.6059\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0219 - accuracy: 0.9975 - val_loss: 1.7116 - val_accuracy: 0.6010\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0181 - accuracy: 0.9975 - val_loss: 1.6877 - val_accuracy: 0.5813\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 1.7549 - val_accuracy: 0.5961\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 1.7104 - val_accuracy: 0.5961\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 1.7170 - val_accuracy: 0.5764\n",
      "2-conv-128-nodes-1-dense-1653490353\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_31 (Conv1D)          (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 41, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_32 (Conv1D)          (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 6, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 768)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,582\n",
      "Trainable params: 264,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 7s 105ms/step - loss: 1.5654 - accuracy: 0.3016 - val_loss: 1.4721 - val_accuracy: 0.3350\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 1.4375 - accuracy: 0.3486 - val_loss: 1.4302 - val_accuracy: 0.3892\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 1.3469 - accuracy: 0.4302 - val_loss: 1.3977 - val_accuracy: 0.3990\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 1.2905 - accuracy: 0.4351 - val_loss: 1.2987 - val_accuracy: 0.4286\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 1.2068 - accuracy: 0.5056 - val_loss: 1.3021 - val_accuracy: 0.4680\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 1.0971 - accuracy: 0.5426 - val_loss: 1.2680 - val_accuracy: 0.4680\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 1.0116 - accuracy: 0.6020 - val_loss: 1.1830 - val_accuracy: 0.5123\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.9106 - accuracy: 0.6119 - val_loss: 1.0985 - val_accuracy: 0.5961\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.8211 - accuracy: 0.6749 - val_loss: 1.0901 - val_accuracy: 0.5961\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.7750 - accuracy: 0.6922 - val_loss: 1.0956 - val_accuracy: 0.5616\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.6212 - accuracy: 0.7602 - val_loss: 1.2105 - val_accuracy: 0.5616\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.5884 - accuracy: 0.7664 - val_loss: 1.1693 - val_accuracy: 0.5862\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.5111 - accuracy: 0.8257 - val_loss: 1.0676 - val_accuracy: 0.6158\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.3982 - accuracy: 0.8677 - val_loss: 1.1479 - val_accuracy: 0.6355\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.3173 - accuracy: 0.8925 - val_loss: 1.1416 - val_accuracy: 0.6305\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.2950 - accuracy: 0.8937 - val_loss: 1.1945 - val_accuracy: 0.5961\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.2007 - accuracy: 0.9295 - val_loss: 1.2405 - val_accuracy: 0.6305\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1373 - accuracy: 0.9716 - val_loss: 1.2961 - val_accuracy: 0.6404\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1117 - accuracy: 0.9740 - val_loss: 1.2905 - val_accuracy: 0.6404\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.1124 - accuracy: 0.9802 - val_loss: 1.3439 - val_accuracy: 0.6108\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.1031 - accuracy: 0.9753 - val_loss: 1.3812 - val_accuracy: 0.6355\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 3s 102ms/step - loss: 0.1236 - accuracy: 0.9604 - val_loss: 1.4592 - val_accuracy: 0.6256\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0671 - accuracy: 0.9889 - val_loss: 1.4109 - val_accuracy: 0.6650\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0406 - accuracy: 0.9926 - val_loss: 1.4166 - val_accuracy: 0.6650\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.4297 - val_accuracy: 0.6453\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.5125 - val_accuracy: 0.6552\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.5568 - val_accuracy: 0.6453\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.5371 - val_accuracy: 0.6700\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.6355\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6064 - val_accuracy: 0.6552\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6034 - val_accuracy: 0.6601\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.6154 - val_accuracy: 0.6552\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.6569 - val_accuracy: 0.6552\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.6701 - val_accuracy: 0.6502\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.6777 - val_accuracy: 0.6552\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.6859 - val_accuracy: 0.6650\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.7035 - val_accuracy: 0.6601\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7278 - val_accuracy: 0.6601\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.7312 - val_accuracy: 0.6700\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.7395 - val_accuracy: 0.6700\n",
      "3-conv-128-nodes-1-dense-1653490429\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_33 (Conv1D)          (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 41, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPoolin  (None, 6, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 6, 128)            163968    \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 1, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 346,630\n",
      "Trainable params: 346,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 7s 101ms/step - loss: 1.5969 - accuracy: 0.2979 - val_loss: 1.5147 - val_accuracy: 0.3448\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 1.4775 - accuracy: 0.3721 - val_loss: 1.5134 - val_accuracy: 0.3300\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 1.4042 - accuracy: 0.4166 - val_loss: 1.4215 - val_accuracy: 0.3842\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 1.3216 - accuracy: 0.4475 - val_loss: 1.3945 - val_accuracy: 0.3892\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 1.2865 - accuracy: 0.4487 - val_loss: 1.3268 - val_accuracy: 0.3941\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.1884 - accuracy: 0.4957 - val_loss: 1.3081 - val_accuracy: 0.4581\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 1.0978 - accuracy: 0.5179 - val_loss: 1.2708 - val_accuracy: 0.4433\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.9749 - accuracy: 0.5921 - val_loss: 1.2625 - val_accuracy: 0.5320\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.9110 - accuracy: 0.6341 - val_loss: 1.1725 - val_accuracy: 0.5616\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 0.7512 - accuracy: 0.7256 - val_loss: 1.2308 - val_accuracy: 0.5369\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.6792 - accuracy: 0.7355 - val_loss: 1.1038 - val_accuracy: 0.6010\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.5448 - accuracy: 0.7738 - val_loss: 1.2086 - val_accuracy: 0.5369\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.4424 - accuracy: 0.8405 - val_loss: 1.1879 - val_accuracy: 0.6256\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.3386 - accuracy: 0.8677 - val_loss: 1.3960 - val_accuracy: 0.5616\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.3356 - accuracy: 0.8714 - val_loss: 1.2979 - val_accuracy: 0.5764\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.2229 - accuracy: 0.9246 - val_loss: 1.2132 - val_accuracy: 0.6700\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1447 - accuracy: 0.9617 - val_loss: 1.2657 - val_accuracy: 0.6601\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.1176 - accuracy: 0.9604 - val_loss: 1.3290 - val_accuracy: 0.6355\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.1557 - accuracy: 0.9493 - val_loss: 1.2520 - val_accuracy: 0.6404\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1150 - accuracy: 0.9617 - val_loss: 1.3819 - val_accuracy: 0.6650\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.0986 - accuracy: 0.9716 - val_loss: 1.4612 - val_accuracy: 0.6404\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0667 - accuracy: 0.9827 - val_loss: 1.4896 - val_accuracy: 0.6650\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.0641 - accuracy: 0.9790 - val_loss: 1.6936 - val_accuracy: 0.6502\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.0649 - accuracy: 0.9839 - val_loss: 1.5131 - val_accuracy: 0.6749\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.0349 - accuracy: 0.9926 - val_loss: 1.8288 - val_accuracy: 0.6355\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 1.6237 - val_accuracy: 0.6502\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0124 - accuracy: 0.9975 - val_loss: 1.6048 - val_accuracy: 0.6552\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 1.6585 - val_accuracy: 0.6650\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.0394 - accuracy: 0.9839 - val_loss: 1.6650 - val_accuracy: 0.6798\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0210 - accuracy: 0.9951 - val_loss: 1.7239 - val_accuracy: 0.6552\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7824 - val_accuracy: 0.6601\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7994 - val_accuracy: 0.6650\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8041 - val_accuracy: 0.6650\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8272 - val_accuracy: 0.6700\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8501 - val_accuracy: 0.6650\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8522 - val_accuracy: 0.6700\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 9.7888e-04 - accuracy: 1.0000 - val_loss: 1.8658 - val_accuracy: 0.6650\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 8.7712e-04 - accuracy: 1.0000 - val_loss: 1.8879 - val_accuracy: 0.6650\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 8.0462e-04 - accuracy: 1.0000 - val_loss: 1.8950 - val_accuracy: 0.6601\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 7.2103e-04 - accuracy: 1.0000 - val_loss: 1.9008 - val_accuracy: 0.6552\n",
      "1-conv-32-nodes-2-dense-1653490502\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_36 (Conv1D)          (None, 250, 32)           352       \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 41, 32)           0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 1312)              0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 32)                42016     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,622\n",
      "Trainable params: 43,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 5s 45ms/step - loss: 1.6387 - accuracy: 0.3103 - val_loss: 1.5544 - val_accuracy: 0.3054\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.4489 - accuracy: 0.3659 - val_loss: 1.4158 - val_accuracy: 0.3842\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3396 - accuracy: 0.4240 - val_loss: 1.3737 - val_accuracy: 0.4039\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2733 - accuracy: 0.4635 - val_loss: 1.3843 - val_accuracy: 0.3744\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.2453 - accuracy: 0.4747 - val_loss: 1.2990 - val_accuracy: 0.4483\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1717 - accuracy: 0.5080 - val_loss: 1.3113 - val_accuracy: 0.4384\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.1337 - accuracy: 0.5303 - val_loss: 1.2622 - val_accuracy: 0.4778\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0765 - accuracy: 0.5525 - val_loss: 1.2771 - val_accuracy: 0.4581\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0606 - accuracy: 0.5389 - val_loss: 1.2237 - val_accuracy: 0.5123\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0125 - accuracy: 0.5723 - val_loss: 1.2560 - val_accuracy: 0.4532\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9859 - accuracy: 0.6044 - val_loss: 1.1887 - val_accuracy: 0.4877\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.9287 - accuracy: 0.6131 - val_loss: 1.2082 - val_accuracy: 0.5123\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9164 - accuracy: 0.6391 - val_loss: 1.2090 - val_accuracy: 0.5172\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.8447 - accuracy: 0.6638 - val_loss: 1.1739 - val_accuracy: 0.5419\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.8235 - accuracy: 0.6749 - val_loss: 1.1812 - val_accuracy: 0.5369\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.7877 - accuracy: 0.6922 - val_loss: 1.2156 - val_accuracy: 0.5320\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7924 - accuracy: 0.6885 - val_loss: 1.1693 - val_accuracy: 0.5517\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7047 - accuracy: 0.7318 - val_loss: 1.1478 - val_accuracy: 0.5616\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6573 - accuracy: 0.7577 - val_loss: 1.1629 - val_accuracy: 0.5764\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6302 - accuracy: 0.7750 - val_loss: 1.1709 - val_accuracy: 0.5567\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6030 - accuracy: 0.7812 - val_loss: 1.2346 - val_accuracy: 0.5419\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.5882 - accuracy: 0.7824 - val_loss: 1.1849 - val_accuracy: 0.5764\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.5583 - accuracy: 0.8010 - val_loss: 1.2390 - val_accuracy: 0.5172\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.5468 - accuracy: 0.7973 - val_loss: 1.1715 - val_accuracy: 0.5616\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5174 - accuracy: 0.8010 - val_loss: 1.1533 - val_accuracy: 0.5419\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.5070 - accuracy: 0.8208 - val_loss: 1.2053 - val_accuracy: 0.5714\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4390 - accuracy: 0.8603 - val_loss: 1.2780 - val_accuracy: 0.5665\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.4485 - accuracy: 0.8245 - val_loss: 1.2602 - val_accuracy: 0.5419\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.3845 - accuracy: 0.8875 - val_loss: 1.3403 - val_accuracy: 0.5123\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3805 - accuracy: 0.8752 - val_loss: 1.2984 - val_accuracy: 0.5764\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.3528 - accuracy: 0.8764 - val_loss: 1.2909 - val_accuracy: 0.5665\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.3550 - accuracy: 0.8776 - val_loss: 1.2649 - val_accuracy: 0.5714\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3245 - accuracy: 0.8863 - val_loss: 1.2883 - val_accuracy: 0.5616\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.3077 - accuracy: 0.8986 - val_loss: 1.4185 - val_accuracy: 0.5419\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.3307 - accuracy: 0.8888 - val_loss: 1.4518 - val_accuracy: 0.5419\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.2855 - accuracy: 0.8900 - val_loss: 1.3714 - val_accuracy: 0.5665\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2491 - accuracy: 0.9258 - val_loss: 1.4165 - val_accuracy: 0.5517\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.2488 - accuracy: 0.9197 - val_loss: 1.3761 - val_accuracy: 0.5616\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.2146 - accuracy: 0.9357 - val_loss: 1.4519 - val_accuracy: 0.5369\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.2334 - accuracy: 0.9271 - val_loss: 1.4615 - val_accuracy: 0.5419\n",
      "2-conv-32-nodes-2-dense-1653490548\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_37 (Conv1D)          (None, 250, 32)           352       \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, 41, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_38 (Conv1D)          (None, 41, 32)            10272     \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 18,054\n",
      "Trainable params: 18,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 7s 81ms/step - loss: 1.6935 - accuracy: 0.2855 - val_loss: 1.5838 - val_accuracy: 0.2562\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 1.5037 - accuracy: 0.3189 - val_loss: 1.4938 - val_accuracy: 0.2660\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.4422 - accuracy: 0.3263 - val_loss: 1.4415 - val_accuracy: 0.3103\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 1.4122 - accuracy: 0.3523 - val_loss: 1.4269 - val_accuracy: 0.3596\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.3741 - accuracy: 0.3486 - val_loss: 1.3892 - val_accuracy: 0.3399\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.3223 - accuracy: 0.3548 - val_loss: 1.4025 - val_accuracy: 0.3695\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 1.3099 - accuracy: 0.4030 - val_loss: 1.3286 - val_accuracy: 0.4138\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.2540 - accuracy: 0.4388 - val_loss: 1.2868 - val_accuracy: 0.4483\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.2480 - accuracy: 0.4611 - val_loss: 1.2582 - val_accuracy: 0.4828\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.1822 - accuracy: 0.5117 - val_loss: 1.2534 - val_accuracy: 0.4828\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.1713 - accuracy: 0.4920 - val_loss: 1.2583 - val_accuracy: 0.4729\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.0973 - accuracy: 0.5266 - val_loss: 1.2009 - val_accuracy: 0.5074\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 1.0446 - accuracy: 0.5587 - val_loss: 1.1829 - val_accuracy: 0.5123\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 1.0186 - accuracy: 0.5661 - val_loss: 1.1867 - val_accuracy: 0.5271\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.0074 - accuracy: 0.5834 - val_loss: 1.2373 - val_accuracy: 0.4680\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.9590 - accuracy: 0.5933 - val_loss: 1.1526 - val_accuracy: 0.5419\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.9182 - accuracy: 0.6193 - val_loss: 1.1714 - val_accuracy: 0.5172\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.8603 - accuracy: 0.6452 - val_loss: 1.2057 - val_accuracy: 0.5517\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.8892 - accuracy: 0.6205 - val_loss: 1.2063 - val_accuracy: 0.5764\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.8265 - accuracy: 0.6613 - val_loss: 1.1274 - val_accuracy: 0.5714\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7909 - accuracy: 0.6749 - val_loss: 1.1313 - val_accuracy: 0.5419\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.7637 - accuracy: 0.6811 - val_loss: 1.1424 - val_accuracy: 0.5517\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6962 - accuracy: 0.7231 - val_loss: 1.2405 - val_accuracy: 0.5813\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6704 - accuracy: 0.7305 - val_loss: 1.1952 - val_accuracy: 0.5517\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6800 - accuracy: 0.7206 - val_loss: 1.2180 - val_accuracy: 0.5616\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6628 - accuracy: 0.7404 - val_loss: 1.2013 - val_accuracy: 0.5665\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6103 - accuracy: 0.7515 - val_loss: 1.2292 - val_accuracy: 0.5567\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6301 - accuracy: 0.7454 - val_loss: 1.1551 - val_accuracy: 0.6010\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.5720 - accuracy: 0.7775 - val_loss: 1.3007 - val_accuracy: 0.5123\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5464 - accuracy: 0.7948 - val_loss: 1.1815 - val_accuracy: 0.5911\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.5094 - accuracy: 0.8146 - val_loss: 1.2505 - val_accuracy: 0.5517\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.4616 - accuracy: 0.8418 - val_loss: 1.2087 - val_accuracy: 0.6010\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.4655 - accuracy: 0.8368 - val_loss: 1.3517 - val_accuracy: 0.5961\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.4229 - accuracy: 0.8541 - val_loss: 1.3259 - val_accuracy: 0.5961\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.4026 - accuracy: 0.8578 - val_loss: 1.4656 - val_accuracy: 0.5813\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.4025 - accuracy: 0.8566 - val_loss: 1.3896 - val_accuracy: 0.5665\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.3492 - accuracy: 0.8813 - val_loss: 1.4254 - val_accuracy: 0.5517\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.3778 - accuracy: 0.8628 - val_loss: 1.3703 - val_accuracy: 0.5961\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3226 - accuracy: 0.8999 - val_loss: 1.4545 - val_accuracy: 0.5714\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.2954 - accuracy: 0.9073 - val_loss: 1.4974 - val_accuracy: 0.6010\n",
      "3-conv-32-nodes-2-dense-1653490581\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_39 (Conv1D)          (None, 250, 32)           352       \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPoolin  (None, 41, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_40 (Conv1D)          (None, 41, 32)            10272     \n",
      "                                                                 \n",
      " max_pooling1d_40 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_41 (Conv1D)          (None, 6, 32)             10272     \n",
      "                                                                 \n",
      " max_pooling1d_41 (MaxPoolin  (None, 1, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,206\n",
      "Trainable params: 23,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 6s 69ms/step - loss: 1.6994 - accuracy: 0.2534 - val_loss: 1.6458 - val_accuracy: 0.2463\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.5788 - accuracy: 0.3337 - val_loss: 1.5411 - val_accuracy: 0.3596\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.4969 - accuracy: 0.3436 - val_loss: 1.4819 - val_accuracy: 0.3695\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.4578 - accuracy: 0.3572 - val_loss: 1.4665 - val_accuracy: 0.3695\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.4233 - accuracy: 0.3956 - val_loss: 1.4461 - val_accuracy: 0.3596\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.3697 - accuracy: 0.4388 - val_loss: 1.4260 - val_accuracy: 0.3596\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.3269 - accuracy: 0.4376 - val_loss: 1.3835 - val_accuracy: 0.3793\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.2934 - accuracy: 0.4598 - val_loss: 1.3365 - val_accuracy: 0.4138\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 1.2329 - accuracy: 0.4660 - val_loss: 1.3671 - val_accuracy: 0.4187\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.2358 - accuracy: 0.4771 - val_loss: 1.3091 - val_accuracy: 0.4581\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.1658 - accuracy: 0.4808 - val_loss: 1.2505 - val_accuracy: 0.5025\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.1135 - accuracy: 0.5167 - val_loss: 1.2409 - val_accuracy: 0.5025\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 1.0567 - accuracy: 0.5649 - val_loss: 1.2715 - val_accuracy: 0.4729\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.9597 - accuracy: 0.6094 - val_loss: 1.1580 - val_accuracy: 0.5271\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.9348 - accuracy: 0.6168 - val_loss: 1.2696 - val_accuracy: 0.4778\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.9105 - accuracy: 0.6267 - val_loss: 1.2371 - val_accuracy: 0.4680\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.8231 - accuracy: 0.6737 - val_loss: 1.1668 - val_accuracy: 0.5271\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7346 - accuracy: 0.7070 - val_loss: 1.1751 - val_accuracy: 0.5222\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7786 - accuracy: 0.6947 - val_loss: 1.1273 - val_accuracy: 0.5025\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6741 - accuracy: 0.7330 - val_loss: 1.0739 - val_accuracy: 0.5517\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6053 - accuracy: 0.7750 - val_loss: 1.1011 - val_accuracy: 0.6108\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.5559 - accuracy: 0.7874 - val_loss: 1.2112 - val_accuracy: 0.5468\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.5544 - accuracy: 0.7738 - val_loss: 1.1191 - val_accuracy: 0.5616\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.5098 - accuracy: 0.7998 - val_loss: 1.1560 - val_accuracy: 0.5764\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.4626 - accuracy: 0.8294 - val_loss: 1.2609 - val_accuracy: 0.5517\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.4023 - accuracy: 0.8628 - val_loss: 1.4420 - val_accuracy: 0.5271\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.4200 - accuracy: 0.8381 - val_loss: 1.1954 - val_accuracy: 0.5714\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.4043 - accuracy: 0.8443 - val_loss: 1.1445 - val_accuracy: 0.5911\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.3195 - accuracy: 0.8875 - val_loss: 1.2157 - val_accuracy: 0.5961\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2862 - accuracy: 0.9048 - val_loss: 1.4049 - val_accuracy: 0.5764\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.3050 - accuracy: 0.8974 - val_loss: 1.2966 - val_accuracy: 0.6256\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.2482 - accuracy: 0.9036 - val_loss: 1.2894 - val_accuracy: 0.5813\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.2214 - accuracy: 0.9320 - val_loss: 1.4493 - val_accuracy: 0.5764\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.2102 - accuracy: 0.9283 - val_loss: 1.4638 - val_accuracy: 0.5616\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.1986 - accuracy: 0.9283 - val_loss: 1.4045 - val_accuracy: 0.5862\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.1531 - accuracy: 0.9543 - val_loss: 1.4433 - val_accuracy: 0.5862\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.1363 - accuracy: 0.9629 - val_loss: 1.5200 - val_accuracy: 0.5862\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.1616 - accuracy: 0.9543 - val_loss: 1.7757 - val_accuracy: 0.5714\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.4021 - accuracy: 0.8813 - val_loss: 1.6947 - val_accuracy: 0.5862\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3096 - accuracy: 0.8949 - val_loss: 1.4443 - val_accuracy: 0.5813\n",
      "1-conv-64-nodes-2-dense-1653490612\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_42 (Conv1D)          (None, 250, 64)           704       \n",
      "                                                                 \n",
      " max_pooling1d_42 (MaxPoolin  (None, 41, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 2624)              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 64)                168000    \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,254\n",
      "Trainable params: 173,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 6s 51ms/step - loss: 1.5702 - accuracy: 0.3412 - val_loss: 1.4968 - val_accuracy: 0.3695\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.4220 - accuracy: 0.3832 - val_loss: 1.4182 - val_accuracy: 0.3892\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.3118 - accuracy: 0.4438 - val_loss: 1.4235 - val_accuracy: 0.3744\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2612 - accuracy: 0.4561 - val_loss: 1.3044 - val_accuracy: 0.4335\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.1900 - accuracy: 0.5142 - val_loss: 1.2730 - val_accuracy: 0.4877\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 1.1504 - accuracy: 0.5068 - val_loss: 1.2403 - val_accuracy: 0.5123\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0786 - accuracy: 0.5464 - val_loss: 1.2114 - val_accuracy: 0.5271\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.9892 - accuracy: 0.5810 - val_loss: 1.2047 - val_accuracy: 0.5468\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.9634 - accuracy: 0.6032 - val_loss: 1.2820 - val_accuracy: 0.4975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.8992 - accuracy: 0.6242 - val_loss: 1.1672 - val_accuracy: 0.5123\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.8305 - accuracy: 0.6539 - val_loss: 1.1504 - val_accuracy: 0.5517\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.7979 - accuracy: 0.6774 - val_loss: 1.2203 - val_accuracy: 0.5172\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.7348 - accuracy: 0.7058 - val_loss: 1.2359 - val_accuracy: 0.5271\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6778 - accuracy: 0.7169 - val_loss: 1.2548 - val_accuracy: 0.4975\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6232 - accuracy: 0.7627 - val_loss: 1.2326 - val_accuracy: 0.5419\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.5678 - accuracy: 0.7726 - val_loss: 1.1569 - val_accuracy: 0.5468\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.5156 - accuracy: 0.7998 - val_loss: 1.3224 - val_accuracy: 0.5074\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.5096 - accuracy: 0.8072 - val_loss: 1.2150 - val_accuracy: 0.5468\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.4625 - accuracy: 0.8220 - val_loss: 1.2048 - val_accuracy: 0.5369\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.4294 - accuracy: 0.8356 - val_loss: 1.1829 - val_accuracy: 0.5320\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.3715 - accuracy: 0.8727 - val_loss: 1.1965 - val_accuracy: 0.5369\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.3349 - accuracy: 0.8764 - val_loss: 1.1882 - val_accuracy: 0.5025\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.2966 - accuracy: 0.9036 - val_loss: 1.1891 - val_accuracy: 0.5123\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.2450 - accuracy: 0.9172 - val_loss: 1.2298 - val_accuracy: 0.5419\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.2746 - accuracy: 0.9073 - val_loss: 1.3570 - val_accuracy: 0.5123\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3419 - accuracy: 0.8838 - val_loss: 1.5438 - val_accuracy: 0.4877\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.2711 - accuracy: 0.9061 - val_loss: 1.2858 - val_accuracy: 0.5665\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.1765 - accuracy: 0.9555 - val_loss: 1.4014 - val_accuracy: 0.5567\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1801 - accuracy: 0.9493 - val_loss: 1.3121 - val_accuracy: 0.5567\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1221 - accuracy: 0.9716 - val_loss: 1.3909 - val_accuracy: 0.5665\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1081 - accuracy: 0.9802 - val_loss: 1.5254 - val_accuracy: 0.5862\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1003 - accuracy: 0.9765 - val_loss: 1.4587 - val_accuracy: 0.5665\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1008 - accuracy: 0.9778 - val_loss: 1.3849 - val_accuracy: 0.5665\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0843 - accuracy: 0.9839 - val_loss: 1.5554 - val_accuracy: 0.5567\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0795 - accuracy: 0.9876 - val_loss: 1.5358 - val_accuracy: 0.5714\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0810 - accuracy: 0.9815 - val_loss: 1.6210 - val_accuracy: 0.5813\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0628 - accuracy: 0.9901 - val_loss: 1.5139 - val_accuracy: 0.6010\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.0600 - accuracy: 0.9864 - val_loss: 1.6045 - val_accuracy: 0.5665\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.0548 - accuracy: 0.9901 - val_loss: 1.7242 - val_accuracy: 0.5616\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.0731 - accuracy: 0.9778 - val_loss: 1.6026 - val_accuracy: 0.5764\n",
      "2-conv-64-nodes-2-dense-1653490642\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_43 (Conv1D)          (None, 250, 64)           704       \n",
      "                                                                 \n",
      " max_pooling1d_43 (MaxPoolin  (None, 41, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_44 (Conv1D)          (None, 41, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_44 (MaxPoolin  (None, 6, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,918\n",
      "Trainable params: 70,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 6s 86ms/step - loss: 1.6055 - accuracy: 0.3103 - val_loss: 1.4897 - val_accuracy: 0.3300\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.4315 - accuracy: 0.3782 - val_loss: 1.4238 - val_accuracy: 0.3744\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.3652 - accuracy: 0.4203 - val_loss: 1.3749 - val_accuracy: 0.3892\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 1.2991 - accuracy: 0.4512 - val_loss: 1.3821 - val_accuracy: 0.4236\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.2903 - accuracy: 0.4685 - val_loss: 1.3090 - val_accuracy: 0.4384\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.2082 - accuracy: 0.4994 - val_loss: 1.2435 - val_accuracy: 0.4483\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.1502 - accuracy: 0.5204 - val_loss: 1.2311 - val_accuracy: 0.4926\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.0877 - accuracy: 0.5488 - val_loss: 1.2855 - val_accuracy: 0.4335\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 1.0693 - accuracy: 0.5637 - val_loss: 1.1740 - val_accuracy: 0.5222\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.9797 - accuracy: 0.6082 - val_loss: 1.1979 - val_accuracy: 0.4828\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.9227 - accuracy: 0.6267 - val_loss: 1.1490 - val_accuracy: 0.5369\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.8300 - accuracy: 0.6910 - val_loss: 1.1445 - val_accuracy: 0.5468\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.7756 - accuracy: 0.6836 - val_loss: 1.0691 - val_accuracy: 0.5813\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.7075 - accuracy: 0.7281 - val_loss: 1.1892 - val_accuracy: 0.6059\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6641 - accuracy: 0.7478 - val_loss: 1.1120 - val_accuracy: 0.5813\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.5723 - accuracy: 0.7787 - val_loss: 1.0701 - val_accuracy: 0.5862\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.4996 - accuracy: 0.8257 - val_loss: 1.1328 - val_accuracy: 0.5862\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.4702 - accuracy: 0.8331 - val_loss: 1.2392 - val_accuracy: 0.5567\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.4193 - accuracy: 0.8418 - val_loss: 1.1054 - val_accuracy: 0.5961\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.3776 - accuracy: 0.8702 - val_loss: 1.1795 - val_accuracy: 0.5764\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.3601 - accuracy: 0.8739 - val_loss: 1.1327 - val_accuracy: 0.6158\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.2774 - accuracy: 0.9098 - val_loss: 1.1616 - val_accuracy: 0.6256\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.2542 - accuracy: 0.9197 - val_loss: 1.2206 - val_accuracy: 0.6355\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.2124 - accuracy: 0.9308 - val_loss: 1.1929 - val_accuracy: 0.6502\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1966 - accuracy: 0.9419 - val_loss: 1.3298 - val_accuracy: 0.6355\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.1471 - accuracy: 0.9629 - val_loss: 1.2590 - val_accuracy: 0.6207\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.1307 - accuracy: 0.9679 - val_loss: 1.5150 - val_accuracy: 0.6305\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.1606 - accuracy: 0.9456 - val_loss: 1.4044 - val_accuracy: 0.5911\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1150 - accuracy: 0.9703 - val_loss: 1.3363 - val_accuracy: 0.6305\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0876 - accuracy: 0.9864 - val_loss: 1.5149 - val_accuracy: 0.6305\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0856 - accuracy: 0.9815 - val_loss: 1.5350 - val_accuracy: 0.6404\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.2862 - accuracy: 0.9110 - val_loss: 1.9217 - val_accuracy: 0.5764\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.4067 - accuracy: 0.8776 - val_loss: 1.1984 - val_accuracy: 0.6207\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1273 - accuracy: 0.9666 - val_loss: 1.4735 - val_accuracy: 0.6453\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0644 - accuracy: 0.9913 - val_loss: 1.4303 - val_accuracy: 0.6404\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0598 - accuracy: 0.9864 - val_loss: 1.6430 - val_accuracy: 0.6552\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0521 - accuracy: 0.9864 - val_loss: 1.5261 - val_accuracy: 0.6700\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 1.6680 - val_accuracy: 0.6355\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0431 - accuracy: 0.9913 - val_loss: 1.4838 - val_accuracy: 0.6404\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.5925 - val_accuracy: 0.6502\n",
      "3-conv-64-nodes-2-dense-1653490681\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_45 (Conv1D)          (None, 250, 64)           704       \n",
      "                                                                 \n",
      " max_pooling1d_45 (MaxPoolin  (None, 41, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_46 (Conv1D)          (None, 41, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_46 (MaxPoolin  (None, 6, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_47 (Conv1D)          (None, 6, 64)             41024     \n",
      "                                                                 \n",
      " max_pooling1d_47 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,462\n",
      "Trainable params: 91,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 6s 66ms/step - loss: 1.6256 - accuracy: 0.2756 - val_loss: 1.5451 - val_accuracy: 0.2709\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.4963 - accuracy: 0.3078 - val_loss: 1.5297 - val_accuracy: 0.3202\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.4631 - accuracy: 0.3201 - val_loss: 1.4737 - val_accuracy: 0.2759\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 1.4259 - accuracy: 0.3251 - val_loss: 1.4336 - val_accuracy: 0.2906\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 1.3831 - accuracy: 0.3337 - val_loss: 1.4358 - val_accuracy: 0.3498\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.3535 - accuracy: 0.3894 - val_loss: 1.3796 - val_accuracy: 0.4089\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 1.3091 - accuracy: 0.4351 - val_loss: 1.2961 - val_accuracy: 0.4384\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.2673 - accuracy: 0.4549 - val_loss: 1.2738 - val_accuracy: 0.4483\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.1539 - accuracy: 0.5105 - val_loss: 1.2155 - val_accuracy: 0.4532\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.1034 - accuracy: 0.5352 - val_loss: 1.2308 - val_accuracy: 0.4877\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.0100 - accuracy: 0.5587 - val_loss: 1.2473 - val_accuracy: 0.4483\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.9502 - accuracy: 0.6020 - val_loss: 1.3534 - val_accuracy: 0.4631\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.9553 - accuracy: 0.6106 - val_loss: 1.2837 - val_accuracy: 0.4975\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.8161 - accuracy: 0.6687 - val_loss: 1.1891 - val_accuracy: 0.5567\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.7325 - accuracy: 0.7219 - val_loss: 1.1096 - val_accuracy: 0.5665\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6190 - accuracy: 0.7565 - val_loss: 1.1015 - val_accuracy: 0.5862\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.5293 - accuracy: 0.7948 - val_loss: 1.1226 - val_accuracy: 0.6404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.4343 - accuracy: 0.8331 - val_loss: 1.1940 - val_accuracy: 0.6010\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.4092 - accuracy: 0.8492 - val_loss: 1.2490 - val_accuracy: 0.5961\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.3795 - accuracy: 0.8480 - val_loss: 1.2247 - val_accuracy: 0.6158\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.2685 - accuracy: 0.9073 - val_loss: 1.2694 - val_accuracy: 0.6108\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.2170 - accuracy: 0.9295 - val_loss: 1.3453 - val_accuracy: 0.6256\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.2382 - accuracy: 0.9258 - val_loss: 1.2459 - val_accuracy: 0.6108\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.2379 - accuracy: 0.9085 - val_loss: 1.2188 - val_accuracy: 0.6404\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.2800 - accuracy: 0.8900 - val_loss: 1.2855 - val_accuracy: 0.6453\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.1542 - accuracy: 0.9518 - val_loss: 1.3417 - val_accuracy: 0.6552\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0771 - accuracy: 0.9864 - val_loss: 1.4651 - val_accuracy: 0.6502\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0839 - accuracy: 0.9765 - val_loss: 1.5638 - val_accuracy: 0.6256\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0720 - accuracy: 0.9839 - val_loss: 1.5991 - val_accuracy: 0.6305\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0599 - accuracy: 0.9765 - val_loss: 1.7595 - val_accuracy: 0.6010\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0558 - accuracy: 0.9839 - val_loss: 1.5189 - val_accuracy: 0.6305\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0337 - accuracy: 0.9938 - val_loss: 1.5974 - val_accuracy: 0.6256\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 1.6925 - val_accuracy: 0.6650\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0209 - accuracy: 0.9963 - val_loss: 1.7289 - val_accuracy: 0.6502\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0156 - accuracy: 0.9975 - val_loss: 1.7070 - val_accuracy: 0.6502\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 1.7725 - val_accuracy: 0.6453\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.7934 - val_accuracy: 0.6453\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.8278 - val_accuracy: 0.6453\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8234 - val_accuracy: 0.6355\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8593 - val_accuracy: 0.6404\n",
      "1-conv-128-nodes-2-dense-1653490721\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_48 (Conv1D)          (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d_48 (MaxPoolin  (None, 41, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 5248)              0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 128)               671872    \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 690,566\n",
      "Trainable params: 690,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 6s 76ms/step - loss: 1.4972 - accuracy: 0.3325 - val_loss: 1.3990 - val_accuracy: 0.3990\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3124 - accuracy: 0.4376 - val_loss: 1.3822 - val_accuracy: 0.3941\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.2403 - accuracy: 0.4611 - val_loss: 1.3207 - val_accuracy: 0.4384\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.1685 - accuracy: 0.4944 - val_loss: 1.2770 - val_accuracy: 0.4532\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.0484 - accuracy: 0.5525 - val_loss: 1.1966 - val_accuracy: 0.5123\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.9462 - accuracy: 0.6143 - val_loss: 1.3553 - val_accuracy: 0.5025\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.8782 - accuracy: 0.6329 - val_loss: 1.4257 - val_accuracy: 0.4680\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.8896 - accuracy: 0.6527 - val_loss: 1.1978 - val_accuracy: 0.5123\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7402 - accuracy: 0.7058 - val_loss: 1.1532 - val_accuracy: 0.5714\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6177 - accuracy: 0.7503 - val_loss: 1.1416 - val_accuracy: 0.5862\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.4950 - accuracy: 0.8084 - val_loss: 1.2634 - val_accuracy: 0.5320\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.4536 - accuracy: 0.8232 - val_loss: 1.2604 - val_accuracy: 0.5862\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.3626 - accuracy: 0.8640 - val_loss: 1.2364 - val_accuracy: 0.5468\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.3911 - accuracy: 0.8356 - val_loss: 1.2249 - val_accuracy: 0.5468\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.3678 - accuracy: 0.8480 - val_loss: 1.2866 - val_accuracy: 0.5862\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3266 - accuracy: 0.8640 - val_loss: 1.3656 - val_accuracy: 0.5517\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.2831 - accuracy: 0.9011 - val_loss: 1.4629 - val_accuracy: 0.5665\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1910 - accuracy: 0.9357 - val_loss: 1.4490 - val_accuracy: 0.5764\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.1928 - accuracy: 0.9221 - val_loss: 1.3200 - val_accuracy: 0.6108\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.1141 - accuracy: 0.9617 - val_loss: 1.3465 - val_accuracy: 0.6108\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0868 - accuracy: 0.9703 - val_loss: 1.4338 - val_accuracy: 0.6059\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0735 - accuracy: 0.9740 - val_loss: 1.4251 - val_accuracy: 0.6305\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0561 - accuracy: 0.9839 - val_loss: 1.5233 - val_accuracy: 0.6256\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0491 - accuracy: 0.9827 - val_loss: 1.6497 - val_accuracy: 0.6010\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0588 - accuracy: 0.9815 - val_loss: 1.5259 - val_accuracy: 0.6256\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0519 - accuracy: 0.9802 - val_loss: 1.6380 - val_accuracy: 0.6207\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0409 - accuracy: 0.9827 - val_loss: 1.6985 - val_accuracy: 0.5862\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0342 - accuracy: 0.9876 - val_loss: 1.7551 - val_accuracy: 0.6108\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0304 - accuracy: 0.9876 - val_loss: 1.6600 - val_accuracy: 0.6108\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0211 - accuracy: 0.9913 - val_loss: 1.7150 - val_accuracy: 0.6059\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0181 - accuracy: 0.9913 - val_loss: 1.7697 - val_accuracy: 0.6207\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 1.7791 - val_accuracy: 0.5961\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 1.8456 - val_accuracy: 0.6059\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0295 - accuracy: 0.9889 - val_loss: 1.8278 - val_accuracy: 0.6108\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0393 - accuracy: 0.9827 - val_loss: 2.1018 - val_accuracy: 0.5813\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0580 - accuracy: 0.9827 - val_loss: 1.8103 - val_accuracy: 0.6010\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 2.0815 - val_accuracy: 0.5862\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7164 - accuracy: 0.7936 - val_loss: 1.5475 - val_accuracy: 0.5222\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.2379 - accuracy: 0.9172 - val_loss: 1.5376 - val_accuracy: 0.5764\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0930 - accuracy: 0.9740 - val_loss: 1.6839 - val_accuracy: 0.5714\n",
      "2-conv-128-nodes-2-dense-1653490766\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_49 (Conv1D)          (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d_49 (MaxPoolin  (None, 41, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_50 (Conv1D)          (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_50 (MaxPoolin  (None, 6, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_50 (Flatten)        (None, 768)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 281,094\n",
      "Trainable params: 281,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 5s 90ms/step - loss: 1.6002 - accuracy: 0.2868 - val_loss: 1.5303 - val_accuracy: 0.3251\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.4512 - accuracy: 0.3795 - val_loss: 1.4884 - val_accuracy: 0.3744\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.3931 - accuracy: 0.3894 - val_loss: 1.3889 - val_accuracy: 0.3744\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.3069 - accuracy: 0.4376 - val_loss: 1.3215 - val_accuracy: 0.4138\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 1.2456 - accuracy: 0.4536 - val_loss: 1.2883 - val_accuracy: 0.4187\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.1739 - accuracy: 0.5142 - val_loss: 1.3156 - val_accuracy: 0.4335\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.1076 - accuracy: 0.5476 - val_loss: 1.1661 - val_accuracy: 0.5172\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.9445 - accuracy: 0.6292 - val_loss: 1.2550 - val_accuracy: 0.4581\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.8934 - accuracy: 0.6341 - val_loss: 1.3499 - val_accuracy: 0.5172\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.8058 - accuracy: 0.6675 - val_loss: 1.1832 - val_accuracy: 0.5025\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.7209 - accuracy: 0.7231 - val_loss: 1.1093 - val_accuracy: 0.6059\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.5863 - accuracy: 0.7664 - val_loss: 1.0327 - val_accuracy: 0.6552\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.4822 - accuracy: 0.8121 - val_loss: 1.1054 - val_accuracy: 0.6552\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.4305 - accuracy: 0.8418 - val_loss: 1.0333 - val_accuracy: 0.6552\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.3462 - accuracy: 0.8789 - val_loss: 1.1496 - val_accuracy: 0.6404\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.2498 - accuracy: 0.9122 - val_loss: 1.3273 - val_accuracy: 0.5961\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.2815 - accuracy: 0.8962 - val_loss: 1.2835 - val_accuracy: 0.6305\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.1771 - accuracy: 0.9407 - val_loss: 1.4238 - val_accuracy: 0.6158\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 0.1628 - accuracy: 0.9506 - val_loss: 1.4867 - val_accuracy: 0.6305\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.2809 - accuracy: 0.9098 - val_loss: 1.1832 - val_accuracy: 0.6158\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.1072 - accuracy: 0.9827 - val_loss: 1.4207 - val_accuracy: 0.6453\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.1125 - accuracy: 0.9642 - val_loss: 1.4434 - val_accuracy: 0.6601\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.1888 - accuracy: 0.9357 - val_loss: 1.5809 - val_accuracy: 0.6158\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.1685 - accuracy: 0.9506 - val_loss: 1.4243 - val_accuracy: 0.6453\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0572 - accuracy: 0.9901 - val_loss: 1.4936 - val_accuracy: 0.6404\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0301 - accuracy: 0.9988 - val_loss: 1.5170 - val_accuracy: 0.6601\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0170 - accuracy: 0.9988 - val_loss: 1.5029 - val_accuracy: 0.6650\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0303 - accuracy: 0.9913 - val_loss: 1.5410 - val_accuracy: 0.6404\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.0165 - accuracy: 0.9988 - val_loss: 1.5972 - val_accuracy: 0.6502\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 55ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.6184 - val_accuracy: 0.6453\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.6911 - val_accuracy: 0.6502\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.7049 - val_accuracy: 0.6552\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.7185 - val_accuracy: 0.6650\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7487 - val_accuracy: 0.6650\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7905 - val_accuracy: 0.6552\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8030 - val_accuracy: 0.6650\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8232 - val_accuracy: 0.6601\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8429 - val_accuracy: 0.6552\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.8659 - val_accuracy: 0.6601\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8745 - val_accuracy: 0.6650\n",
      "3-conv-128-nodes-2-dense-1653490831\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_51 (Conv1D)          (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d_51 (MaxPoolin  (None, 41, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_52 (Conv1D)          (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_52 (MaxPoolin  (None, 6, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 6, 128)            163968    \n",
      "                                                                 \n",
      " max_pooling1d_53 (MaxPoolin  (None, 1, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_52 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      " flatten_53 (Flatten)        (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 363,142\n",
      "Trainable params: 363,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 9s 121ms/step - loss: 1.5774 - accuracy: 0.2979 - val_loss: 1.5368 - val_accuracy: 0.2759\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 1.5047 - accuracy: 0.3375 - val_loss: 1.4764 - val_accuracy: 0.3153\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 1.4603 - accuracy: 0.3177 - val_loss: 1.4825 - val_accuracy: 0.3350\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 1.4389 - accuracy: 0.3152 - val_loss: 1.4352 - val_accuracy: 0.3251\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 1.3836 - accuracy: 0.3375 - val_loss: 1.3833 - val_accuracy: 0.3645\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.3246 - accuracy: 0.4339 - val_loss: 1.3585 - val_accuracy: 0.4483\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.2842 - accuracy: 0.4388 - val_loss: 1.3486 - val_accuracy: 0.4236\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.2307 - accuracy: 0.4623 - val_loss: 1.2542 - val_accuracy: 0.4828\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 1.1137 - accuracy: 0.5315 - val_loss: 1.2212 - val_accuracy: 0.4877\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 1.0038 - accuracy: 0.5810 - val_loss: 1.1637 - val_accuracy: 0.5222\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.8643 - accuracy: 0.6205 - val_loss: 1.1865 - val_accuracy: 0.5517\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.7784 - accuracy: 0.6922 - val_loss: 1.0042 - val_accuracy: 0.5665\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.6863 - accuracy: 0.7219 - val_loss: 1.1588 - val_accuracy: 0.5567\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.5244 - accuracy: 0.8146 - val_loss: 1.3186 - val_accuracy: 0.5764\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.3797 - accuracy: 0.8690 - val_loss: 1.4532 - val_accuracy: 0.5911\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.3610 - accuracy: 0.8714 - val_loss: 1.3143 - val_accuracy: 0.5567\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.2527 - accuracy: 0.9098 - val_loss: 1.4911 - val_accuracy: 0.5616\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.2040 - accuracy: 0.9271 - val_loss: 1.3349 - val_accuracy: 0.6158\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.2042 - accuracy: 0.9295 - val_loss: 1.3310 - val_accuracy: 0.6256\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.1581 - accuracy: 0.9506 - val_loss: 1.3854 - val_accuracy: 0.6453\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.1021 - accuracy: 0.9666 - val_loss: 1.7370 - val_accuracy: 0.5911\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0872 - accuracy: 0.9740 - val_loss: 1.5192 - val_accuracy: 0.6404\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.0380 - accuracy: 0.9876 - val_loss: 1.5055 - val_accuracy: 0.6700\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 1.5867 - val_accuracy: 0.6404\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.0268 - accuracy: 0.9889 - val_loss: 1.6774 - val_accuracy: 0.6502\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.6066 - val_accuracy: 0.6552\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.6757 - val_accuracy: 0.6700\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7133 - val_accuracy: 0.6847\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7519 - val_accuracy: 0.6847\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7794 - val_accuracy: 0.6847\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 9.9724e-04 - accuracy: 1.0000 - val_loss: 1.7952 - val_accuracy: 0.6798\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 8.7789e-04 - accuracy: 1.0000 - val_loss: 1.8174 - val_accuracy: 0.6847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 8.0009e-04 - accuracy: 1.0000 - val_loss: 1.8317 - val_accuracy: 0.6847\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 7.1248e-04 - accuracy: 1.0000 - val_loss: 1.8498 - val_accuracy: 0.6897\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 6.4544e-04 - accuracy: 1.0000 - val_loss: 1.8649 - val_accuracy: 0.6897\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 5.9210e-04 - accuracy: 1.0000 - val_loss: 1.8820 - val_accuracy: 0.6897\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 5.4485e-04 - accuracy: 1.0000 - val_loss: 1.8928 - val_accuracy: 0.6897\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 5.0338e-04 - accuracy: 1.0000 - val_loss: 1.9060 - val_accuracy: 0.6847\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 4.6932e-04 - accuracy: 1.0000 - val_loss: 1.9178 - val_accuracy: 0.6897\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 4.3487e-04 - accuracy: 1.0000 - val_loss: 1.9282 - val_accuracy: 0.6897\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32,64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            \n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "            model = Sequential()\n",
    "            model.add(layers.Conv1D(layer_size, kernel_size=(10), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "            model.add(layers.MaxPooling1D(pool_size=(6)))\n",
    "           \n",
    "            \n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "                \n",
    "                model.add(layers.Conv1D(layer_size, kernel_size=(10),padding=\"same\",activation='relu'))\n",
    "                model.add(layers.MaxPooling1D(pool_size=(6)))\n",
    "                \n",
    "            \n",
    "            \n",
    "            model.add(layers.Flatten())\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(layers.Dense(layer_size, activation='relu'))\n",
    "                \n",
    "                \n",
    "                     \n",
    "            model.add(layers.Dense(6, activation='sigmoid'))\n",
    "            model.add(layers.Flatten())\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "            opt = keras.optimizers.Adam(lr=0.001)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "            model.summary()\n",
    "            model_history=model.fit(X_train, y_train,batch_size=32, epochs=40, validation_data=(X_test, y_test),callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-conv-128-nodes-0-dense-1653530628\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 41, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 41, 128)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 6, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 128)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 6, 128)            163968    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 1, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330,118\n",
      "Trainable params: 330,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 24s 279ms/step - loss: 1.6030 - accuracy: 0.2794 - val_loss: 1.5589 - val_accuracy: 0.2906\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 1.5256 - accuracy: 0.3078 - val_loss: 1.5126 - val_accuracy: 0.2759\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 4s 148ms/step - loss: 1.5098 - accuracy: 0.3090 - val_loss: 1.5286 - val_accuracy: 0.2857\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 4s 152ms/step - loss: 1.4938 - accuracy: 0.2868 - val_loss: 1.4981 - val_accuracy: 0.3054\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 1.4596 - accuracy: 0.3103 - val_loss: 1.4822 - val_accuracy: 0.2857\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 1.4522 - accuracy: 0.3313 - val_loss: 1.4890 - val_accuracy: 0.3350\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 1.4087 - accuracy: 0.3671 - val_loss: 1.3995 - val_accuracy: 0.3202\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 4s 147ms/step - loss: 1.3948 - accuracy: 0.3436 - val_loss: 1.4646 - val_accuracy: 0.3350\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 1.3599 - accuracy: 0.4129 - val_loss: 1.3360 - val_accuracy: 0.4236\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 1.3202 - accuracy: 0.4388 - val_loss: 1.3115 - val_accuracy: 0.4729\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 3s 137ms/step - loss: 1.2916 - accuracy: 0.4512 - val_loss: 1.2841 - val_accuracy: 0.4532\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 4s 142ms/step - loss: 1.2398 - accuracy: 0.4771 - val_loss: 1.2561 - val_accuracy: 0.4975\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 1.2546 - accuracy: 0.4895 - val_loss: 1.3335 - val_accuracy: 0.4680\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 1.2112 - accuracy: 0.5093 - val_loss: 1.2112 - val_accuracy: 0.5271\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 1.1566 - accuracy: 0.5451 - val_loss: 1.2570 - val_accuracy: 0.5320\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 1.1008 - accuracy: 0.5624 - val_loss: 1.1314 - val_accuracy: 0.5665\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 4s 141ms/step - loss: 1.0452 - accuracy: 0.5933 - val_loss: 1.1442 - val_accuracy: 0.6059\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 4s 141ms/step - loss: 1.0320 - accuracy: 0.5810 - val_loss: 1.1762 - val_accuracy: 0.5813\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 0.9795 - accuracy: 0.6032 - val_loss: 1.0904 - val_accuracy: 0.6059\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 4s 160ms/step - loss: 1.0316 - accuracy: 0.6218 - val_loss: 1.1438 - val_accuracy: 0.6256\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 4s 160ms/step - loss: 0.9669 - accuracy: 0.6193 - val_loss: 1.0743 - val_accuracy: 0.6158\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 4s 152ms/step - loss: 0.9183 - accuracy: 0.6440 - val_loss: 1.1576 - val_accuracy: 0.6010\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 4s 152ms/step - loss: 1.0046 - accuracy: 0.6007 - val_loss: 1.0757 - val_accuracy: 0.6207\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.9176 - accuracy: 0.6539 - val_loss: 1.0970 - val_accuracy: 0.5813\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 0.8794 - accuracy: 0.6761 - val_loss: 1.1648 - val_accuracy: 0.5961\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.8067 - accuracy: 0.7058 - val_loss: 1.0509 - val_accuracy: 0.6158\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 3s 132ms/step - loss: 0.7771 - accuracy: 0.7268 - val_loss: 1.1479 - val_accuracy: 0.6108\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.7704 - accuracy: 0.7182 - val_loss: 1.0570 - val_accuracy: 0.6453\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 0.7474 - accuracy: 0.7404 - val_loss: 1.0473 - val_accuracy: 0.6700\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 3s 130ms/step - loss: 0.7126 - accuracy: 0.7404 - val_loss: 1.0418 - val_accuracy: 0.6601\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 4s 157ms/step - loss: 0.6985 - accuracy: 0.7441 - val_loss: 1.0359 - val_accuracy: 0.6453\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 4s 149ms/step - loss: 0.6704 - accuracy: 0.7540 - val_loss: 1.0430 - val_accuracy: 0.6700\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 4s 149ms/step - loss: 0.6106 - accuracy: 0.7899 - val_loss: 1.0370 - val_accuracy: 0.6552\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.5980 - accuracy: 0.7948 - val_loss: 1.0522 - val_accuracy: 0.6601\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6177 - accuracy: 0.7800 - val_loss: 1.0700 - val_accuracy: 0.6700\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 4s 151ms/step - loss: 0.6104 - accuracy: 0.7911 - val_loss: 1.1209 - val_accuracy: 0.6502\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 3s 128ms/step - loss: 0.5879 - accuracy: 0.8022 - val_loss: 1.0992 - val_accuracy: 0.6453\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 3s 137ms/step - loss: 0.5349 - accuracy: 0.8121 - val_loss: 1.0855 - val_accuracy: 0.6700\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 3s 127ms/step - loss: 0.5611 - accuracy: 0.8158 - val_loss: 1.1070 - val_accuracy: 0.6256\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 4s 142ms/step - loss: 0.5378 - accuracy: 0.8109 - val_loss: 1.1227 - val_accuracy: 0.6355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(2, 128, 0, int(time.time()))\n",
    "print(NAME)\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(128, kernel_size=10, activation='relu',kernel_regularizer=keras.regularizers.l2(1e-4), input_shape=(X_train.shape[1],1)))\n",
    "model.add(layers.MaxPooling1D(pool_size=(6)))\n",
    "model.add(layers.Dropout(0.5))                       \n",
    "                \n",
    "model.add(layers.Conv1D(128, kernel_size=10,padding=\"same\",kernel_regularizer=keras.regularizers.l2(1e-4),activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=(6)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv1D(128, kernel_size=10,padding=\"same\",kernel_regularizer=keras.regularizers.l2(l2=1e-4),activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=(6)))\n",
    "               \n",
    "            \n",
    "            \n",
    "model.add(layers.Flatten())  \n",
    "\n",
    "model.add(layers.Dense(6 , bias_regularizer=keras.regularizers.L2(1e-4), activation='sigmoid'))\n",
    "model.add(layers.Flatten())\n",
    "tensorboard = TensorBoard(log_dir=\"CNNfinal/{}\".format(NAME))\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model.summary()\n",
    "model_history=model.fit(X_train, y_train,batch_size=32, epochs=40, validation_data=(X_test, y_test),callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 4s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "# PREDICTIONS\n",
    "predictions = model.predict(X_test)\n",
    "predictions=predictions.argmax(axis=1)\n",
    "predictions = predictions.astype(int).flatten()\n",
    "\n",
    "\n",
    "# ACTUAL LABELS\n",
    "actual=y_test.argmax(axis=1)\n",
    "actual = actual.astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "cm = confusion_matrix(actual, predictions)\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#saving the model\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 250, 128)          1408      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 41, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 41, 128)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 6, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 128)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 6, 128)            163968    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 1, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330,118\n",
      "Trainable params: 330,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('C:/Users/Jawher/Desktop/jihed/model.h5')\n",
    "print(\"model loaded\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<librosa.display.AdaptiveWaveplot at 0x1f8502f9ca0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, sampling_rate = librosa.load('C:/Users/Jawher/Desktop/jihed/Conversation Sound.wav')\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveshow(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, sample_rate = librosa.load('C:/Users/Jawher/Desktop/jihed/Conversation Sound.wav', res_type='kaiser_fast',duration=7,sr=44000,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "#extracting features\n",
    "spectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128,fmax=8000) \n",
    "db_spec = librosa.power_to_db(spectrogram)\n",
    "log_spectrogram = np.mean(db_spec, axis = 0)\n",
    "mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "mfcc=np.mean(mfcc,axis=0)\n",
    "zcr = librosa.feature.zero_crossing_rate(y=X)\n",
    "zcr = np.mean(zcr, axis= 0)\n",
    "#converting features to numpy arrays\n",
    "ls = np.array(log_spectrogram )\n",
    "zcr1=np.array(zcr )\n",
    "mf=np.array(mfcc)\n",
    "#appending all arrays into a single one\n",
    "live=np.append(ls,zcr1)\n",
    "live=np.append(live,mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "mean = np.mean(live, axis=0)\n",
    "std = np.std(live, axis=0)\n",
    "livedata = (live - mean)/std\n",
    "# TURN DATA INTO ARRAYS FOR KERAS\n",
    "livedata = np.array(livedata)\n",
    "#resizing data to fit the model\n",
    "livedata=np.resize(livedata,259)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the data inside a dataframe then making it  3d to fit the tensor\n",
    "livedf2 = livedata\n",
    "livedf2= pd.DataFrame(data=livedf2)\n",
    "livedf2 = livedf2.stack().to_frame().T\n",
    "twodim= np.expand_dims(livedf2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 965ms/step\n"
     ]
    }
   ],
   "source": [
    "#live prediction in detail\n",
    "livepreds = model.predict(twodim, \n",
    "                         batch_size=128, \n",
    "                         verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['calm'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#live prediction\n",
    "livepreds=livepreds.argmax(axis=1)\n",
    "liveabc = livepreds.astype(int).flatten()\n",
    "livepredictions = (lb.inverse_transform((liveabc)))\n",
    "livepredictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 3D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809, 259)\n",
      "(203, 259)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN TEST SPLIT DATA\n",
    "train,test = train_test_split(df_combined, test_size=0.2, random_state=0,\n",
    "                               stratify=df_combined[['gender','actor']])\n",
    "\n",
    "X_train = train.iloc[:, 3:]\n",
    "y_train = train.iloc[:,:2].drop(columns=['gender'])\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test = test.iloc[:,3:]\n",
    "y_test = test.iloc[:,:2].drop(columns=['gender'])\n",
    "print(X_test.shape)\n",
    "# TURN DATA INTO ARRAYS FOR KERAS\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# RESHAPE TO INCLUDE 3D TENSOR\n",
    "X_train = X_train[:,:,np.newaxis]\n",
    "X_test = X_test[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train1 = X_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test1 = X_test.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "SVM = svm.SVC(C=10,gamma=0.0001, kernel='rbf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.0001)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.fit(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['calm' 'happy' 'angry' 'fear' 'fear' 'happy' 'calm' 'calm' 'angry' 'fear'\n",
      " 'calm' 'happy' 'neutral' 'angry' 'neutral' 'happy' 'neutral' 'sad'\n",
      " 'neutral' 'angry' 'calm' 'angry' 'angry' 'sad' 'fear' 'happy' 'sad'\n",
      " 'happy' 'fear' 'neutral' 'happy' 'happy' 'happy' 'happy' 'happy' 'happy'\n",
      " 'angry' 'angry' 'happy' 'angry' 'fear' 'sad' 'angry' 'fear' 'fear' 'calm'\n",
      " 'fear' 'happy' 'angry' 'angry' 'angry' 'sad' 'calm' 'fear' 'calm' 'sad'\n",
      " 'fear' 'sad' 'sad' 'neutral' 'fear' 'angry' 'calm' 'calm' 'sad' 'happy'\n",
      " 'fear' 'happy' 'angry' 'happy' 'happy' 'sad' 'sad' 'sad' 'angry' 'angry'\n",
      " 'fear' 'happy' 'angry' 'sad' 'calm' 'happy' 'sad' 'happy' 'happy' 'fear'\n",
      " 'calm' 'calm' 'neutral' 'sad' 'calm' 'fear' 'calm' 'fear' 'calm' 'calm'\n",
      " 'angry' 'happy' 'sad' 'angry' 'calm' 'angry' 'calm' 'angry' 'angry'\n",
      " 'angry' 'angry' 'neutral' 'calm' 'happy' 'neutral' 'happy' 'angry' 'sad'\n",
      " 'calm' 'calm' 'happy' 'sad' 'sad' 'neutral' 'fear' 'angry' 'happy' 'fear'\n",
      " 'neutral' 'angry' 'angry' 'calm' 'happy' 'neutral' 'calm' 'neutral' 'sad'\n",
      " 'angry' 'calm' 'calm' 'angry' 'calm' 'angry' 'happy' 'fear' 'angry' 'sad'\n",
      " 'calm' 'calm' 'happy' 'calm' 'angry' 'angry' 'angry' 'fear' 'angry' 'sad'\n",
      " 'fear' 'fear' 'sad' 'calm' 'sad' 'sad' 'happy' 'neutral' 'fear' 'angry'\n",
      " 'fear' 'sad' 'sad' 'fear' 'angry' 'fear' 'calm' 'happy' 'neutral' 'happy'\n",
      " 'calm' 'fear' 'fear' 'angry' 'happy' 'fear' 'fear' 'happy' 'fear' 'happy'\n",
      " 'sad' 'calm' 'sad' 'calm' 'happy' 'angry' 'fear' 'happy' 'sad' 'happy'\n",
      " 'neutral' 'angry' 'calm' 'sad' 'happy' 'neutral' 'happy' 'angry' 'angry'\n",
      " 'calm']\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = SVM.predict(X_test1)\n",
    "print(svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6354679802955665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the SVM model on our test data set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "SVM_predictions=SVM.predict(X_test1)\n",
    "\n",
    "cm=confusion_matrix(y_test,SVM_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN 2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN-Model-1653532080\n",
      "(809, 6)\n",
      "(809, 259)\n",
      "Epoch 1/40\n",
      "26/26 [==============================] - 16s 188ms/step - loss: 1.9145 - accuracy: 0.2583 - val_loss: 1.5162 - val_accuracy: 0.3350\n",
      "Epoch 2/40\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.6277 - accuracy: 0.3486 - val_loss: 1.4264 - val_accuracy: 0.4089\n",
      "Epoch 3/40\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.4965 - accuracy: 0.3956 - val_loss: 1.4026 - val_accuracy: 0.4187\n",
      "Epoch 4/40\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 1.4082 - accuracy: 0.4487 - val_loss: 1.3630 - val_accuracy: 0.4631\n",
      "Epoch 5/40\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 1.4661 - accuracy: 0.4054 - val_loss: 1.3341 - val_accuracy: 0.4532\n",
      "Epoch 6/40\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.3993 - accuracy: 0.4215 - val_loss: 1.3419 - val_accuracy: 0.4532\n",
      "Epoch 7/40\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 1.3404 - accuracy: 0.4648 - val_loss: 1.3272 - val_accuracy: 0.4433\n",
      "Epoch 8/40\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.2991 - accuracy: 0.4957 - val_loss: 1.3103 - val_accuracy: 0.4729\n",
      "Epoch 9/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.2900 - accuracy: 0.4808 - val_loss: 1.3042 - val_accuracy: 0.4581\n",
      "Epoch 10/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.2574 - accuracy: 0.4784 - val_loss: 1.3035 - val_accuracy: 0.4729\n",
      "Epoch 11/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.2289 - accuracy: 0.4957 - val_loss: 1.3030 - val_accuracy: 0.4631\n",
      "Epoch 12/40\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.1693 - accuracy: 0.5402 - val_loss: 1.2616 - val_accuracy: 0.5025\n",
      "Epoch 13/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.1867 - accuracy: 0.5204 - val_loss: 1.2940 - val_accuracy: 0.5074\n",
      "Epoch 14/40\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.2106 - accuracy: 0.5117 - val_loss: 1.2582 - val_accuracy: 0.4828\n",
      "Epoch 15/40\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.1672 - accuracy: 0.5439 - val_loss: 1.2645 - val_accuracy: 0.4975\n",
      "Epoch 16/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.1246 - accuracy: 0.5612 - val_loss: 1.2494 - val_accuracy: 0.5074\n",
      "Epoch 17/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.0940 - accuracy: 0.5587 - val_loss: 1.2405 - val_accuracy: 0.4975\n",
      "Epoch 18/40\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 1.1246 - accuracy: 0.5426 - val_loss: 1.2501 - val_accuracy: 0.5074\n",
      "Epoch 19/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 1.0707 - accuracy: 0.5686 - val_loss: 1.2578 - val_accuracy: 0.5025\n",
      "Epoch 20/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.0704 - accuracy: 0.5773 - val_loss: 1.2319 - val_accuracy: 0.5074\n",
      "Epoch 21/40\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.9914 - accuracy: 0.6304 - val_loss: 1.2227 - val_accuracy: 0.5320\n",
      "Epoch 22/40\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.0038 - accuracy: 0.5909 - val_loss: 1.2236 - val_accuracy: 0.5025\n",
      "Epoch 23/40\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.9864 - accuracy: 0.6267 - val_loss: 1.2094 - val_accuracy: 0.5123\n",
      "Epoch 24/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.9853 - accuracy: 0.6230 - val_loss: 1.2185 - val_accuracy: 0.5123\n",
      "Epoch 25/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.9720 - accuracy: 0.6366 - val_loss: 1.2193 - val_accuracy: 0.4926\n",
      "Epoch 26/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.9457 - accuracy: 0.6415 - val_loss: 1.2098 - val_accuracy: 0.4926\n",
      "Epoch 27/40\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.9658 - accuracy: 0.6316 - val_loss: 1.2055 - val_accuracy: 0.5271\n",
      "Epoch 28/40\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.9329 - accuracy: 0.6267 - val_loss: 1.2161 - val_accuracy: 0.5369\n",
      "Epoch 29/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.8805 - accuracy: 0.6700 - val_loss: 1.2233 - val_accuracy: 0.5222\n",
      "Epoch 30/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8954 - accuracy: 0.6638 - val_loss: 1.1938 - val_accuracy: 0.5222\n",
      "Epoch 31/40\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.8846 - accuracy: 0.6613 - val_loss: 1.1860 - val_accuracy: 0.5222\n",
      "Epoch 32/40\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.8679 - accuracy: 0.6811 - val_loss: 1.2146 - val_accuracy: 0.5419\n",
      "Epoch 33/40\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.8347 - accuracy: 0.6588 - val_loss: 1.2360 - val_accuracy: 0.5369\n",
      "Epoch 34/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8613 - accuracy: 0.6712 - val_loss: 1.2260 - val_accuracy: 0.5369\n",
      "Epoch 35/40\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8496 - accuracy: 0.6799 - val_loss: 1.2370 - val_accuracy: 0.5320\n",
      "Epoch 36/40\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.8300 - accuracy: 0.6613 - val_loss: 1.1895 - val_accuracy: 0.5419\n",
      "Epoch 37/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.7701 - accuracy: 0.7244 - val_loss: 1.1910 - val_accuracy: 0.5320\n",
      "Epoch 38/40\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.7853 - accuracy: 0.6823 - val_loss: 1.1822 - val_accuracy: 0.5419\n",
      "Epoch 39/40\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7591 - accuracy: 0.7120 - val_loss: 1.1913 - val_accuracy: 0.5567\n",
      "Epoch 40/40\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7586 - accuracy: 0.7009 - val_loss: 1.1833 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f856e3cd00>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "NAME = \"{}-Model-{}\".format(\"ANN\", int(time.time()))\n",
    "print(NAME)\n",
    "ann = tf.keras.models.Sequential()\n",
    " #Adding First Hidden Layer\n",
    "ann.add(tf.keras.layers.Dense(units=128,kernel_regularizer=keras.regularizers.l2(1e-4),activation=\"relu\"))\n",
    "ann.add(layers.Dropout(0.4)) \n",
    "#Adding Second Hidden Layer\n",
    "ann.add(tf.keras.layers.Dense(units=128,kernel_regularizer=keras.regularizers.l2(1e-4),activation=\"relu\"))\n",
    "ann.add(layers.Dropout(0.4)) \n",
    "#Adding Output Layer\n",
    "ann.add(tf.keras.layers.Dense(units=6,activation=\"softmax\"))\n",
    "#Compiling ANN\n",
    "tensorboard = TensorBoard(log_dir=\"ANN/{}\".format(NAME))\n",
    "ann.compile(optimizer=\"adam\",loss=\"CategoricalCrossentropy\",metrics=['accuracy'])\n",
    "#Fitting ANN\n",
    "\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "ann.fit(X_train, y_train,batch_size=32, epochs=40, validation_data=(X_test, y_test),callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 5ms/step\n",
      "0.4236453201970443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ann_predictions=ann.predict(X_test)\n",
    "ann_predictions=(ann_predictions > 0.5)\n",
    "#results\n",
    "print(accuracy_score(y_test, ann_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#testing the ANN model on our test data set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ann_predictions=ann.predict(X_test)\n",
    "ann_predictions = (ann_predictions > 0.5) \n",
    "cm1=confusion_matrix(y_test.argmax(axis=1),ann_predictions.argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm1, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB 3D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_test)\n",
    "#y_train= le.transform(y_train)\n",
    "y_test= le.transform(y_test)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "X=X_train1\n",
    "XT=X_test1\n",
    "classifier = classifier.fit(X, y_train)\n",
    "nb_predictions  =  classifier.predict(XT)\n",
    "#results\n",
    "print(accuracy_score(y_test, nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 0 2 2 3 1 1 0 2 1 4 4 2 4 3 4 1 4 0 1 5 0 1 0 2 5 3 2 5 0 2 3 3 5 3 3\n",
      " 0 2 0 2 5 0 2 2 1 2 0 0 3 0 5 4 2 4 2 2 5 5 5 2 0 1 1 1 3 2 2 0 3 4 5 2 1\n",
      " 2 3 2 0 0 5 1 3 5 3 4 2 5 5 4 1 2 3 4 2 1 1 2 3 1 3 4 0 1 0 0 0 5 1 1 2 5\n",
      " 0 3 1 1 4 0 1 0 1 2 0 2 2 5 0 0 1 3 4 5 4 2 3 4 1 2 1 0 3 0 2 5 1 1 0 1 0\n",
      " 0 0 2 0 1 2 2 5 4 4 5 2 4 3 0 2 5 5 2 0 2 1 3 5 3 1 2 2 0 3 2 2 3 3 3 5 1\n",
      " 5 1 3 5 2 3 1 3 0 0 3 5 3 4 3 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy' 'happy' 'angry' 'angry' 'fear' 'angry' 'calm' 'calm' 'angry'\n",
      " 'neutral' 'calm' 'neutral' 'happy' 'angry' 'calm' 'happy' 'neutral'\n",
      " 'calm' 'calm' 'angry' 'calm' 'fear' 'angry' 'calm' 'angry' 'happy' 'sad'\n",
      " 'happy' 'angry' 'neutral' 'happy' 'happy' 'fear' 'happy' 'happy' 'happy'\n",
      " 'angry' 'angry' 'fear' 'angry' 'happy' 'happy' 'angry' 'fear' 'fear'\n",
      " 'calm' 'angry' 'angry' 'angry' 'angry' 'angry' 'calm' 'happy' 'fear'\n",
      " 'calm' 'calm' 'angry' 'calm' 'calm' 'neutral' 'angry' 'angry' 'sad'\n",
      " 'calm' 'happy' 'angry' 'happy' 'neutral' 'angry' 'happy' 'happy' 'happy'\n",
      " 'calm' 'neutral' 'angry' 'angry' 'angry' 'sad' 'angry' 'happy' 'happy'\n",
      " 'happy' 'sad' 'angry' 'happy' 'angry' 'calm' 'calm' 'neutral' 'calm'\n",
      " 'calm' 'happy' 'neutral' 'fear' 'calm' 'calm' 'fear' 'happy' 'calm'\n",
      " 'angry' 'calm' 'fear' 'neutral' 'angry' 'angry' 'angry' 'angry' 'neutral'\n",
      " 'calm' 'happy' 'neutral' 'happy' 'angry' 'sad' 'calm' 'calm' 'angry'\n",
      " 'neutral' 'happy' 'neutral' 'angry' 'angry' 'happy' 'neutral' 'calm'\n",
      " 'angry' 'angry' 'happy' 'angry' 'happy' 'calm' 'neutral' 'sad' 'angry'\n",
      " 'calm' 'happy' 'angry' 'sad' 'angry' 'angry' 'happy' 'happy' 'calm'\n",
      " 'happy' 'calm' 'angry' 'calm' 'angry' 'happy' 'happy' 'fear' 'happy'\n",
      " 'sad' 'sad' 'happy' 'fear' 'calm' 'calm' 'sad' 'angry' 'neutral' 'fear'\n",
      " 'angry' 'happy' 'sad' 'calm' 'fear' 'angry' 'happy' 'happy' 'happy'\n",
      " 'neutral' 'angry' 'sad' 'happy' 'angry' 'angry' 'angry' 'fear' 'angry'\n",
      " 'happy' 'happy' 'happy' 'calm' 'calm' 'angry' 'happy' 'neutral' 'angry'\n",
      " 'angry' 'neutral' 'sad' 'neutral' 'happy' 'angry' 'calm' 'neutral'\n",
      " 'happy' 'neutral' 'angry' 'happy' 'fear' 'neutral']\n"
     ]
    }
   ],
   "source": [
    "print(nb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27582486173380083"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 100)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the RF model on our test data set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "rf_predictions=rf.predict(X_test)\n",
    "rf_predictions = (rf_predictions > 0.5) \n",
    "cm=confusion_matrix(y_test.argmax(axis=1),rf_predictions.argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM  2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 249s 8s/step - loss: 1.5036 - accuracy: 0.3486 - val_loss: 1.4873 - val_accuracy: 0.4039\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 203s 8s/step - loss: 1.3774 - accuracy: 0.4413 - val_loss: 1.4876 - val_accuracy: 0.3350\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 210s 8s/step - loss: 1.3224 - accuracy: 0.4635 - val_loss: 1.3704 - val_accuracy: 0.4680\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 211s 8s/step - loss: 1.2797 - accuracy: 0.4784 - val_loss: 1.3153 - val_accuracy: 0.4828\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 204s 8s/step - loss: 1.2392 - accuracy: 0.4932 - val_loss: 1.3502 - val_accuracy: 0.4384\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 214s 8s/step - loss: 1.2088 - accuracy: 0.5253 - val_loss: 1.3203 - val_accuracy: 0.4581\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 221s 9s/step - loss: 1.1572 - accuracy: 0.5266 - val_loss: 1.3155 - val_accuracy: 0.4581\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 220s 9s/step - loss: 1.1326 - accuracy: 0.5513 - val_loss: 1.2871 - val_accuracy: 0.5074\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 209s 8s/step - loss: 1.0954 - accuracy: 0.5414 - val_loss: 1.3216 - val_accuracy: 0.4926\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 209s 8s/step - loss: 1.0483 - accuracy: 0.5834 - val_loss: 1.4345 - val_accuracy: 0.4335\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 210s 8s/step - loss: 1.0571 - accuracy: 0.5686 - val_loss: 1.3276 - val_accuracy: 0.4680\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 211s 8s/step - loss: 0.9604 - accuracy: 0.6180 - val_loss: 1.3444 - val_accuracy: 0.4680\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 212s 8s/step - loss: 0.9390 - accuracy: 0.6403 - val_loss: 1.3937 - val_accuracy: 0.5025\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 211s 8s/step - loss: 0.9030 - accuracy: 0.6625 - val_loss: 1.3461 - val_accuracy: 0.4926\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 215s 8s/step - loss: 0.8775 - accuracy: 0.6625 - val_loss: 1.4799 - val_accuracy: 0.4729\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 215s 8s/step - loss: 0.8460 - accuracy: 0.6724 - val_loss: 1.4019 - val_accuracy: 0.4877\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 220s 9s/step - loss: 0.8180 - accuracy: 0.6786 - val_loss: 1.4813 - val_accuracy: 0.4877\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 301s 11s/step - loss: 0.7467 - accuracy: 0.7132 - val_loss: 1.3988 - val_accuracy: 0.4975\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 653s 26s/step - loss: 0.6805 - accuracy: 0.7169 - val_loss: 1.5278 - val_accuracy: 0.5025\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 1063s 41s/step - loss: 0.6604 - accuracy: 0.7478 - val_loss: 1.6105 - val_accuracy: 0.5074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14a9b11e790>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras  import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "NAME = \"{}-Model-{}\".format(LSTM, int(time.time()))\n",
    "model = Sequential()\n",
    "model.add(layers.Bidirectional(layers.LSTM(256, return_sequences=True), \n",
    "                        input_shape=(X_train.shape[1],1)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(256, return_sequences=True)))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.ELU())\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "tensorboard = TensorBoard(log_dir=r\"C:.\\Users\\21652\\Desktop\\jihed\\LSTM\")\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(0.001,decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,batch_size=32, epochs=20, validation_data=(X_test, y_test),callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 5s 554ms/step\n"
     ]
    }
   ],
   "source": [
    "#testing the LSTM model on our test data set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "model_predictions=model.predict(X_test)\n",
    "model_predictions = (model_predictions > 0.5) \n",
    "cm=confusion_matrix(y_test.argmax(axis=1),model_predictions.argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
